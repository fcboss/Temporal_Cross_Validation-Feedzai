{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:46:02.307103Z",
     "start_time": "2021-02-15T01:46:02.253150Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import re\n",
    "from models import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:46:07.893635Z",
     "start_time": "2021-02-15T01:46:03.580937Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data['as_of_date'] = pd.to_datetime(data.as_of_date)\n",
    "X,y = data.drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float),data['quickstart_label'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:46:09.064506Z",
     "start_time": "2021-02-15T01:46:09.033504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start_Train</th>\n",
       "      <th>Start_Threshold</th>\n",
       "      <th>Start_Test</th>\n",
       "      <th>End_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Start_Train Start_Threshold  Start_Test    End_Test\n",
       "0           0  2011-09-01      2011-12-01  2012-01-01  2012-03-01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_frames = pd.read_csv('data/time_windows_frames.csv')\n",
    "\n",
    "time_frames.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:33:35.914792Z",
     "start_time": "2021-02-15T01:48:43.751552Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 2)\n",
      "(2, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 3)\n",
      "(2, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 4)\n",
      "(2, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 5)\n",
      "(2, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 6)\n",
      "(2, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 7)\n",
      "(2, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 8)\n",
      "(2, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 9)\n",
      "(2, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 10)\n",
      "(2, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 11)\n",
      "(2, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 12)\n",
      "(2, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 13)\n",
      "(2, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 14)\n",
      "(2, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 15)\n",
      "(2, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 16)\n",
      "(2, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 17)\n",
      "(2, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 18)\n",
      "(2, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 19)\n",
      "(2, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 20)\n",
      "(2, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 21)\n",
      "(2, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 22)\n",
      "(2, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 23)\n",
      "(2, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 24)\n",
      "(2, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 25)\n",
      "(2, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 26)\n",
      "(2, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 27)\n",
      "(2, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 28)\n",
      "(2, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 29)\n",
      "(2, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 30)\n",
      "(2, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 31)\n",
      "(2, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 32)\n",
      "(2, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 33)\n",
      "(2, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 34)\n",
      "(2, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 35)\n",
      "(2, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 36)\n",
      "(2, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 37)\n",
      "(2, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 38)\n",
      "(2, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 39)\n",
      "(2, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 40)\n",
      "(2, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 41)\n",
      "(2, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 42)\n",
      "(2, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 43)\n",
      "(2, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 44)\n",
      "(2, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 45)\n",
      "(2, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 46)\n",
      "(2, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 47)\n",
      "(2, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 48)\n",
      "(2, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 5, 49)\n",
      "(2, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(2, 6)\n",
      "(2, 6, 0)\n",
      "(2, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 1)\n",
      "(2, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 2)\n",
      "(2, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 3)\n",
      "(2, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 4)\n",
      "(2, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 5)\n",
      "(2, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 6)\n",
      "(2, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 7)\n",
      "(2, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 8)\n",
      "(2, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 9)\n",
      "(2, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 10)\n",
      "(2, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 11)\n",
      "(2, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 12)\n",
      "(2, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 13)\n",
      "(2, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 14)\n",
      "(2, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 15)\n",
      "(2, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 16)\n",
      "(2, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 17)\n",
      "(2, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 18)\n",
      "(2, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 19)\n",
      "(2, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 20)\n",
      "(2, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 21)\n",
      "(2, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 22)\n",
      "(2, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 23)\n",
      "(2, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 24)\n",
      "(2, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 25)\n",
      "(2, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 26)\n",
      "(2, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 27)\n",
      "(2, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 28)\n",
      "(2, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 29)\n",
      "(2, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 30)\n",
      "(2, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 31)\n",
      "(2, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 32)\n",
      "(2, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 33)\n",
      "(2, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 34)\n",
      "(2, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 35)\n",
      "(2, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 36)\n",
      "(2, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 37)\n",
      "(2, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 38)\n",
      "(2, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 39)\n",
      "(2, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 40)\n",
      "(2, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 41)\n",
      "(2, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 42)\n",
      "(2, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 43)\n",
      "(2, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 44)\n",
      "(2, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 45)\n",
      "(2, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 46)\n",
      "(2, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 47)\n",
      "(2, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 48)\n",
      "(2, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6, 49)\n",
      "(2, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-03-01\n",
      "3\n",
      "(3, 0)\n",
      "(3, 0, 0)\n",
      "(3, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 1)\n",
      "(3, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:    8.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 2)\n",
      "(3, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 3)\n",
      "(3, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 4)\n",
      "(3, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   25.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 5)\n",
      "(3, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 6)\n",
      "(3, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 7)\n",
      "(3, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 8)\n",
      "(3, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:   38.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 9)\n",
      "(3, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   36.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 10)\n",
      "(3, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 11)\n",
      "(3, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 12)\n",
      "(3, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:   50.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 13)\n",
      "(3, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 14)\n",
      "(3, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 15)\n",
      "(3, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 16)\n",
      "(3, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   40.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 17)\n",
      "(3, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 18)\n",
      "(3, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 19)\n",
      "(3, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 20)\n",
      "(3, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:   46.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 21)\n",
      "(3, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:   56.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 22)\n",
      "(3, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:   42.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 23)\n",
      "(3, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:   32.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 24)\n",
      "(3, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 25)\n",
      "(3, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 26)\n",
      "(3, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:   33.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 27)\n",
      "(3, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   43.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 28)\n",
      "(3, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 29)\n",
      "(3, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 30)\n",
      "(3, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 31)\n",
      "(3, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 32)\n",
      "(3, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 33)\n",
      "(3, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   16.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 34)\n",
      "(3, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 35)\n",
      "(3, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:   28.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 36)\n",
      "(3, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 37)\n",
      "(3, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:   16.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 38)\n",
      "(3, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   55.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 39)\n",
      "(3, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 40)\n",
      "(3, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:   41.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 41)\n",
      "(3, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 42)\n",
      "(3, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 43)\n",
      "(3, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:   24.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 44)\n",
      "(3, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 45)\n",
      "(3, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:   25.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 46)\n",
      "(3, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 47)\n",
      "(3, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 48)\n",
      "(3, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 49)\n",
      "(3, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(3, 1, 0)\n",
      "(3, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 1)\n",
      "(3, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 2)\n",
      "(3, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 3)\n",
      "(3, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 4)\n",
      "(3, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 5)\n",
      "(3, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 6)\n",
      "(3, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 7)\n",
      "(3, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 8)\n",
      "(3, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 9)\n",
      "(3, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 10)\n",
      "(3, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 11)\n",
      "(3, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 12)\n",
      "(3, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 13)\n",
      "(3, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 14)\n",
      "(3, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 15)\n",
      "(3, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 16)\n",
      "(3, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 17)\n",
      "(3, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 18)\n",
      "(3, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 19)\n",
      "(3, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 20)\n",
      "(3, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 21)\n",
      "(3, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 22)\n",
      "(3, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 23)\n",
      "(3, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 24)\n",
      "(3, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 25)\n",
      "(3, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 26)\n",
      "(3, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 27)\n",
      "(3, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 28)\n",
      "(3, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 29)\n",
      "(3, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 30)\n",
      "(3, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 31)\n",
      "(3, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 32)\n",
      "(3, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 33)\n",
      "(3, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 34)\n",
      "(3, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 35)\n",
      "(3, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 36)\n",
      "(3, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 37)\n",
      "(3, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 38)\n",
      "(3, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 39)\n",
      "(3, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 40)\n",
      "(3, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 41)\n",
      "(3, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 42)\n",
      "(3, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 43)\n",
      "(3, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 44)\n",
      "(3, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 45)\n",
      "(3, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 46)\n",
      "(3, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 47)\n",
      "(3, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 48)\n",
      "(3, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 1, 49)\n",
      "(3, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(3, 2)\n",
      "(3, 2, 0)\n",
      "(3, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 1)\n",
      "(3, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 2)\n",
      "(3, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 3)\n",
      "(3, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 4)\n",
      "(3, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 5)\n",
      "(3, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 6)\n",
      "(3, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 7)\n",
      "(3, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 8)\n",
      "(3, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 9)\n",
      "(3, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 10)\n",
      "(3, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 11)\n",
      "(3, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 12)\n",
      "(3, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 13)\n",
      "(3, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 14)\n",
      "(3, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 15)\n",
      "(3, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 16)\n",
      "(3, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 17)\n",
      "(3, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 18)\n",
      "(3, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 19)\n",
      "(3, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 20)\n",
      "(3, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 21)\n",
      "(3, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 22)\n",
      "(3, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 23)\n",
      "(3, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 24)\n",
      "(3, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 25)\n",
      "(3, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 26)\n",
      "(3, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 27)\n",
      "(3, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 28)\n",
      "(3, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 29)\n",
      "(3, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 30)\n",
      "(3, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 31)\n",
      "(3, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 32)\n",
      "(3, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 33)\n",
      "(3, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 34)\n",
      "(3, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 35)\n",
      "(3, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 36)\n",
      "(3, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 37)\n",
      "(3, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 38)\n",
      "(3, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 39)\n",
      "(3, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 40)\n",
      "(3, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 41)\n",
      "(3, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 42)\n",
      "(3, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 43)\n",
      "(3, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 44)\n",
      "(3, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 45)\n",
      "(3, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 46)\n",
      "(3, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 47)\n",
      "(3, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 48)\n",
      "(3, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 2, 49)\n",
      "(3, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(3, 3)\n",
      "(3, 3, 0)\n",
      "(3, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 1)\n",
      "(3, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 2)\n",
      "(3, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 3)\n",
      "(3, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 4)\n",
      "(3, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 5)\n",
      "(3, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 6)\n",
      "(3, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 7)\n",
      "(3, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 8)\n",
      "(3, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 9)\n",
      "(3, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 10)\n",
      "(3, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 11)\n",
      "(3, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 12)\n",
      "(3, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 13)\n",
      "(3, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 14)\n",
      "(3, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 15)\n",
      "(3, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 16)\n",
      "(3, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 17)\n",
      "(3, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 18)\n",
      "(3, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 19)\n",
      "(3, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(3, 3, 20)\n",
      "(3, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 21)\n",
      "(3, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 22)\n",
      "(3, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 23)\n",
      "(3, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 24)\n",
      "(3, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 25)\n",
      "(3, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(3, 3, 26)\n",
      "(3, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 27)\n",
      "(3, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 28)\n",
      "(3, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 29)\n",
      "(3, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 30)\n",
      "(3, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 31)\n",
      "(3, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 32)\n",
      "(3, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 33)\n",
      "(3, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 34)\n",
      "(3, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 35)\n",
      "(3, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 36)\n",
      "(3, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 37)\n",
      "(3, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(3, 3, 38)\n",
      "(3, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 39)\n",
      "(3, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 40)\n",
      "(3, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 41)\n",
      "(3, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 42)\n",
      "(3, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 43)\n",
      "(3, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 44)\n",
      "(3, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 45)\n",
      "(3, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 46)\n",
      "(3, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 47)\n",
      "(3, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 48)\n",
      "(3, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 3, 49)\n",
      "(3, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(3, 4)\n",
      "(3, 4, 0)\n",
      "(3, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 1)\n",
      "(3, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 2)\n",
      "(3, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 3)\n",
      "(3, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 4)\n",
      "(3, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:07:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:07:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 5)\n",
      "(3, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:07:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:07:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 6)\n",
      "(3, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:07:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:07:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 7)\n",
      "(3, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:08:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 8)\n",
      "(3, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 9)\n",
      "(3, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 10)\n",
      "(3, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:08:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:08:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 11)\n",
      "(3, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:09:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:09:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 12)\n",
      "(3, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:09:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 13)\n",
      "(3, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:10:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:10:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 14)\n",
      "(3, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 15)\n",
      "(3, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 16)\n",
      "(3, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:10:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:10:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 17)\n",
      "(3, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:11:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 18)\n",
      "(3, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 19)\n",
      "(3, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 20)\n",
      "(3, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 21)\n",
      "(3, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:11:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 22)\n",
      "(3, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:12:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 23)\n",
      "(3, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:12:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 24)\n",
      "(3, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:13:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:13:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 25)\n",
      "(3, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:13:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:13:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 26)\n",
      "(3, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:14:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:14:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 27)\n",
      "(3, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:14:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:14:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 28)\n",
      "(3, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 29)\n",
      "(3, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 30)\n",
      "(3, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:14:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:14:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 31)\n",
      "(3, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:15:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:15:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 32)\n",
      "(3, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 33)\n",
      "(3, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:15:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:15:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 34)\n",
      "(3, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:16:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 35)\n",
      "(3, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:16:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 36)\n",
      "(3, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:16:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 37)\n",
      "(3, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:17:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 38)\n",
      "(3, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:17:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:17:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 39)\n",
      "(3, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:17:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:17:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 40)\n",
      "(3, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:17:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:17:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 41)\n",
      "(3, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:18:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:18:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 42)\n",
      "(3, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:18:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:18:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 43)\n",
      "(3, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:18:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:18:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 44)\n",
      "(3, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:18:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:18:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 45)\n",
      "(3, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 46)\n",
      "(3, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:19:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 47)\n",
      "(3, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:19:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 48)\n",
      "(3, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:19:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 4, 49)\n",
      "(3, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[15:19:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:19:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(3, 5)\n",
      "(3, 5, 0)\n",
      "(3, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 1)\n",
      "(3, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 2)\n",
      "(3, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 3)\n",
      "(3, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 4)\n",
      "(3, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 5)\n",
      "(3, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 6)\n",
      "(3, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 7)\n",
      "(3, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 8)\n",
      "(3, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 9)\n",
      "(3, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 10)\n",
      "(3, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 11)\n",
      "(3, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 12)\n",
      "(3, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 13)\n",
      "(3, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 14)\n",
      "(3, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 15)\n",
      "(3, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 16)\n",
      "(3, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 17)\n",
      "(3, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 18)\n",
      "(3, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 19)\n",
      "(3, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 20)\n",
      "(3, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 21)\n",
      "(3, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 22)\n",
      "(3, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 23)\n",
      "(3, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 24)\n",
      "(3, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 25)\n",
      "(3, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 26)\n",
      "(3, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 27)\n",
      "(3, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 28)\n",
      "(3, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 29)\n",
      "(3, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 30)\n",
      "(3, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 31)\n",
      "(3, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 32)\n",
      "(3, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 33)\n",
      "(3, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 34)\n",
      "(3, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 35)\n",
      "(3, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 36)\n",
      "(3, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 37)\n",
      "(3, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 38)\n",
      "(3, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 39)\n",
      "(3, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 40)\n",
      "(3, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 41)\n",
      "(3, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 42)\n",
      "(3, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 43)\n",
      "(3, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 44)\n",
      "(3, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 45)\n",
      "(3, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 46)\n",
      "(3, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 47)\n",
      "(3, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 48)\n",
      "(3, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 5, 49)\n",
      "(3, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(3, 6)\n",
      "(3, 6, 0)\n",
      "(3, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 1)\n",
      "(3, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 2)\n",
      "(3, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 3)\n",
      "(3, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 4)\n",
      "(3, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 5)\n",
      "(3, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 6)\n",
      "(3, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 7)\n",
      "(3, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 8)\n",
      "(3, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 9)\n",
      "(3, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 10)\n",
      "(3, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 11)\n",
      "(3, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 12)\n",
      "(3, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 13)\n",
      "(3, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 14)\n",
      "(3, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 15)\n",
      "(3, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 16)\n",
      "(3, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 17)\n",
      "(3, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 18)\n",
      "(3, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 19)\n",
      "(3, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 20)\n",
      "(3, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 21)\n",
      "(3, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 22)\n",
      "(3, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 23)\n",
      "(3, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 24)\n",
      "(3, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 25)\n",
      "(3, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 26)\n",
      "(3, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 27)\n",
      "(3, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 28)\n",
      "(3, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 29)\n",
      "(3, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 30)\n",
      "(3, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 31)\n",
      "(3, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 32)\n",
      "(3, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 33)\n",
      "(3, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 34)\n",
      "(3, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 35)\n",
      "(3, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 36)\n",
      "(3, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 37)\n",
      "(3, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 38)\n",
      "(3, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 39)\n",
      "(3, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 40)\n",
      "(3, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 41)\n",
      "(3, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 42)\n",
      "(3, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 43)\n",
      "(3, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 44)\n",
      "(3, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 45)\n",
      "(3, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 46)\n",
      "(3, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 47)\n",
      "(3, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 48)\n",
      "(3, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6, 49)\n",
      "(3, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-04-01\n",
      "4\n",
      "(4, 0)\n",
      "(4, 0, 0)\n",
      "(4, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 1)\n",
      "(4, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 2)\n",
      "(4, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:   58.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 3)\n",
      "(4, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 4)\n",
      "(4, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   30.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 5)\n",
      "(4, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 6)\n",
      "(4, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 7)\n",
      "(4, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 8)\n",
      "(4, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:   47.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 9)\n",
      "(4, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   44.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 10)\n",
      "(4, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 11)\n",
      "(4, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 12)\n",
      "(4, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   44.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 13)\n",
      "(4, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 14)\n",
      "(4, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 15)\n",
      "(4, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 16)\n",
      "(4, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   48.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 17)\n",
      "(4, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:   17.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 18)\n",
      "(4, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 19)\n",
      "(4, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 20)\n",
      "(4, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:   59.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 21)\n",
      "(4, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 22)\n",
      "(4, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:   50.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 23)\n",
      "(4, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:   39.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 24)\n",
      "(4, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:   19.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 25)\n",
      "(4, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:   11.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 26)\n",
      "(4, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:   42.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 27)\n",
      "(4, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   35.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 28)\n",
      "(4, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 29)\n",
      "(4, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 30)\n",
      "(4, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 31)\n",
      "(4, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:   14.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 32)\n",
      "(4, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 33)\n",
      "(4, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   21.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 34)\n",
      "(4, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 35)\n",
      "(4, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:   35.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 36)\n",
      "(4, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   53.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 37)\n",
      "(4, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:   19.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 38)\n",
      "(4, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 39)\n",
      "(4, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 40)\n",
      "(4, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:   50.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 41)\n",
      "(4, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 42)\n",
      "(4, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   47.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 43)\n",
      "(4, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:   28.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 44)\n",
      "(4, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 45)\n",
      "(4, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:   32.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 46)\n",
      "(4, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 47)\n",
      "(4, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 48)\n",
      "(4, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0, 49)\n",
      "(4, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "(4, 1, 0)\n",
      "(4, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 1)\n",
      "(4, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 2)\n",
      "(4, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 3)\n",
      "(4, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 4)\n",
      "(4, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 5)\n",
      "(4, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 6)\n",
      "(4, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 7)\n",
      "(4, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 8)\n",
      "(4, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 9)\n",
      "(4, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 10)\n",
      "(4, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 11)\n",
      "(4, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 12)\n",
      "(4, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 13)\n",
      "(4, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 14)\n",
      "(4, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 15)\n",
      "(4, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 16)\n",
      "(4, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 17)\n",
      "(4, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 18)\n",
      "(4, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 19)\n",
      "(4, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 20)\n",
      "(4, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 21)\n",
      "(4, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 22)\n",
      "(4, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 23)\n",
      "(4, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 24)\n",
      "(4, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 25)\n",
      "(4, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 26)\n",
      "(4, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 27)\n",
      "(4, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 28)\n",
      "(4, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 29)\n",
      "(4, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 30)\n",
      "(4, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 31)\n",
      "(4, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 32)\n",
      "(4, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 33)\n",
      "(4, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 34)\n",
      "(4, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 35)\n",
      "(4, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 36)\n",
      "(4, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 37)\n",
      "(4, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 38)\n",
      "(4, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 39)\n",
      "(4, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 40)\n",
      "(4, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 41)\n",
      "(4, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 42)\n",
      "(4, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 43)\n",
      "(4, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 44)\n",
      "(4, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 45)\n",
      "(4, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 46)\n",
      "(4, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 47)\n",
      "(4, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 48)\n",
      "(4, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 1, 49)\n",
      "(4, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(4, 2)\n",
      "(4, 2, 0)\n",
      "(4, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 1)\n",
      "(4, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 2)\n",
      "(4, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 3)\n",
      "(4, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 4)\n",
      "(4, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 5)\n",
      "(4, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 6)\n",
      "(4, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 7)\n",
      "(4, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 8)\n",
      "(4, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 9)\n",
      "(4, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 10)\n",
      "(4, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 11)\n",
      "(4, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 12)\n",
      "(4, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 13)\n",
      "(4, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 14)\n",
      "(4, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 15)\n",
      "(4, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 16)\n",
      "(4, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 17)\n",
      "(4, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 18)\n",
      "(4, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 19)\n",
      "(4, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 20)\n",
      "(4, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 21)\n",
      "(4, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 22)\n",
      "(4, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 23)\n",
      "(4, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 24)\n",
      "(4, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 25)\n",
      "(4, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 26)\n",
      "(4, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 27)\n",
      "(4, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 28)\n",
      "(4, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 29)\n",
      "(4, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 30)\n",
      "(4, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 31)\n",
      "(4, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 32)\n",
      "(4, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 33)\n",
      "(4, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 34)\n",
      "(4, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 35)\n",
      "(4, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 36)\n",
      "(4, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 37)\n",
      "(4, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 38)\n",
      "(4, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 39)\n",
      "(4, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 40)\n",
      "(4, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 41)\n",
      "(4, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 42)\n",
      "(4, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 43)\n",
      "(4, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 44)\n",
      "(4, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 45)\n",
      "(4, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 46)\n",
      "(4, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 47)\n",
      "(4, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 48)\n",
      "(4, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 2, 49)\n",
      "(4, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(4, 3)\n",
      "(4, 3, 0)\n",
      "(4, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 1)\n",
      "(4, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 2)\n",
      "(4, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 3)\n",
      "(4, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 4)\n",
      "(4, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 5)\n",
      "(4, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 6)\n",
      "(4, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 7)\n",
      "(4, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 8)\n",
      "(4, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 9)\n",
      "(4, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 10)\n",
      "(4, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 11)\n",
      "(4, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 12)\n",
      "(4, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 13)\n",
      "(4, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 14)\n",
      "(4, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 15)\n",
      "(4, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 16)\n",
      "(4, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 17)\n",
      "(4, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 18)\n",
      "(4, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 19)\n",
      "(4, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(4, 3, 20)\n",
      "(4, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 21)\n",
      "(4, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 22)\n",
      "(4, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 23)\n",
      "(4, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 24)\n",
      "(4, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 25)\n",
      "(4, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(4, 3, 26)\n",
      "(4, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 27)\n",
      "(4, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 28)\n",
      "(4, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 29)\n",
      "(4, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 30)\n",
      "(4, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 31)\n",
      "(4, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 32)\n",
      "(4, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 33)\n",
      "(4, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 34)\n",
      "(4, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 35)\n",
      "(4, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 36)\n",
      "(4, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 37)\n",
      "(4, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(4, 3, 38)\n",
      "(4, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 39)\n",
      "(4, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 40)\n",
      "(4, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 41)\n",
      "(4, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 42)\n",
      "(4, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 43)\n",
      "(4, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 44)\n",
      "(4, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 45)\n",
      "(4, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 46)\n",
      "(4, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 47)\n",
      "(4, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 48)\n",
      "(4, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 3, 49)\n",
      "(4, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(4, 4)\n",
      "(4, 4, 0)\n",
      "(4, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:16:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 1)\n",
      "(4, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 2)\n",
      "(4, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 3)\n",
      "(4, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:17:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:17:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 4)\n",
      "(4, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:17:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:17:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 5)\n",
      "(4, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:18:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:18:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 6)\n",
      "(4, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:18:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:18:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 7)\n",
      "(4, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:18:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:18:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 8)\n",
      "(4, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:19:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:19:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 9)\n",
      "(4, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:19:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:19:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 10)\n",
      "(4, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:19:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:19:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 11)\n",
      "(4, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:19:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:19:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 12)\n",
      "(4, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:20:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:20:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 13)\n",
      "(4, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:20:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:20:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 14)\n",
      "(4, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:21:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:21:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 15)\n",
      "(4, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:21:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:21:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 16)\n",
      "(4, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 17)\n",
      "(4, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:21:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:21:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 18)\n",
      "(4, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:22:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:22:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 19)\n",
      "(4, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:22:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 20)\n",
      "(4, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 21)\n",
      "(4, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 22)\n",
      "(4, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:23:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 23)\n",
      "(4, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:23:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:23:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 24)\n",
      "(4, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:24:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:24:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 25)\n",
      "(4, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:25:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:25:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 26)\n",
      "(4, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:25:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:25:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 27)\n",
      "(4, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:26:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:26:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 28)\n",
      "(4, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:26:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:26:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 29)\n",
      "(4, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:26:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:26:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 30)\n",
      "(4, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:26:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:26:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 31)\n",
      "(4, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:27:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:27:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 32)\n",
      "(4, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:27:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:27:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 33)\n",
      "(4, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:28:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:28:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 34)\n",
      "(4, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:28:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:28:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 35)\n",
      "(4, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 36)\n",
      "(4, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 37)\n",
      "(4, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:29:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:29:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 38)\n",
      "(4, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 39)\n",
      "(4, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 40)\n",
      "(4, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:30:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 41)\n",
      "(4, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:30:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 42)\n",
      "(4, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:30:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:30:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 43)\n",
      "(4, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:30:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:30:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 44)\n",
      "(4, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 45)\n",
      "(4, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:31:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 46)\n",
      "(4, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:31:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:31:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 47)\n",
      "(4, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:31:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:31:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 48)\n",
      "(4, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:32:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:32:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 4, 49)\n",
      "(4, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[17:32:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:32:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(4, 5)\n",
      "(4, 5, 0)\n",
      "(4, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 1)\n",
      "(4, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 2)\n",
      "(4, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 3)\n",
      "(4, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 4)\n",
      "(4, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 5)\n",
      "(4, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 6)\n",
      "(4, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 7)\n",
      "(4, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 8)\n",
      "(4, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 9)\n",
      "(4, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 10)\n",
      "(4, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 11)\n",
      "(4, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 12)\n",
      "(4, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 13)\n",
      "(4, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 14)\n",
      "(4, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 15)\n",
      "(4, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 16)\n",
      "(4, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 17)\n",
      "(4, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 18)\n",
      "(4, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 19)\n",
      "(4, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 20)\n",
      "(4, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 21)\n",
      "(4, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 22)\n",
      "(4, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 23)\n",
      "(4, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 24)\n",
      "(4, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 25)\n",
      "(4, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 26)\n",
      "(4, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 27)\n",
      "(4, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 28)\n",
      "(4, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 29)\n",
      "(4, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 30)\n",
      "(4, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 31)\n",
      "(4, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 32)\n",
      "(4, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 33)\n",
      "(4, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 34)\n",
      "(4, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 35)\n",
      "(4, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 36)\n",
      "(4, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 37)\n",
      "(4, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 38)\n",
      "(4, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 39)\n",
      "(4, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 40)\n",
      "(4, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 41)\n",
      "(4, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 42)\n",
      "(4, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 43)\n",
      "(4, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 44)\n",
      "(4, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 45)\n",
      "(4, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 46)\n",
      "(4, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 47)\n",
      "(4, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 48)\n",
      "(4, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 5, 49)\n",
      "(4, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(4, 6)\n",
      "(4, 6, 0)\n",
      "(4, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 1)\n",
      "(4, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 2)\n",
      "(4, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 3)\n",
      "(4, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 4)\n",
      "(4, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 5)\n",
      "(4, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 6)\n",
      "(4, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 7)\n",
      "(4, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 8)\n",
      "(4, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 9)\n",
      "(4, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 10)\n",
      "(4, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 11)\n",
      "(4, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 12)\n",
      "(4, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 13)\n",
      "(4, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 14)\n",
      "(4, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 15)\n",
      "(4, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 16)\n",
      "(4, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 17)\n",
      "(4, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 18)\n",
      "(4, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 19)\n",
      "(4, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 20)\n",
      "(4, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 21)\n",
      "(4, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 22)\n",
      "(4, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 23)\n",
      "(4, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 24)\n",
      "(4, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 25)\n",
      "(4, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 26)\n",
      "(4, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 27)\n",
      "(4, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 28)\n",
      "(4, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 29)\n",
      "(4, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 30)\n",
      "(4, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 31)\n",
      "(4, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 32)\n",
      "(4, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 33)\n",
      "(4, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 34)\n",
      "(4, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 35)\n",
      "(4, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 36)\n",
      "(4, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 37)\n",
      "(4, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 38)\n",
      "(4, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 39)\n",
      "(4, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 40)\n",
      "(4, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 41)\n",
      "(4, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 42)\n",
      "(4, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 43)\n",
      "(4, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 44)\n",
      "(4, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 45)\n",
      "(4, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 46)\n",
      "(4, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 47)\n",
      "(4, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 48)\n",
      "(4, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 49)\n",
      "(4, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-05-01\n",
      "5\n",
      "(5, 0)\n",
      "(5, 0, 0)\n",
      "(5, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 1)\n",
      "(5, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 2)\n",
      "(5, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:   54.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 3)\n",
      "(5, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 4)\n",
      "(5, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   34.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 5)\n",
      "(5, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 6)\n",
      "(5, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 7)\n",
      "(5, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:   12.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 8)\n",
      "(5, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:   49.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 9)\n",
      "(5, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   46.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 10)\n",
      "(5, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   18.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 11)\n",
      "(5, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 12)\n",
      "(5, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 13)\n",
      "(5, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 14)\n",
      "(5, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 15)\n",
      "(5, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 16)\n",
      "(5, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 17)\n",
      "(5, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 18)\n",
      "(5, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    8.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 19)\n",
      "(5, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 20)\n",
      "(5, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:   58.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 21)\n",
      "(5, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 22)\n",
      "(5, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:   51.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 23)\n",
      "(5, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:   40.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 24)\n",
      "(5, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:   20.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 25)\n",
      "(5, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 26)\n",
      "(5, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:   42.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 27)\n",
      "(5, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 28)\n",
      "(5, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 29)\n",
      "(5, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   41.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 30)\n",
      "(5, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 31)\n",
      "(5, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 32)\n",
      "(5, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:   17.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 33)\n",
      "(5, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   21.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 34)\n",
      "(5, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   51.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 35)\n",
      "(5, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:   36.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 36)\n",
      "(5, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 37)\n",
      "(5, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:   20.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 38)\n",
      "(5, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 39)\n",
      "(5, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 40)\n",
      "(5, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:   52.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 41)\n",
      "(5, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 42)\n",
      "(5, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 43)\n",
      "(5, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:   30.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 44)\n",
      "(5, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 45)\n",
      "(5, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:   32.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 46)\n",
      "(5, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 47)\n",
      "(5, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 48)\n",
      "(5, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   36.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 0, 49)\n",
      "(5, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "(5, 1, 0)\n",
      "(5, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 1)\n",
      "(5, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 2)\n",
      "(5, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 3)\n",
      "(5, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 4)\n",
      "(5, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 5)\n",
      "(5, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 6)\n",
      "(5, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 7)\n",
      "(5, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 8)\n",
      "(5, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 9)\n",
      "(5, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 10)\n",
      "(5, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 11)\n",
      "(5, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 12)\n",
      "(5, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 13)\n",
      "(5, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 14)\n",
      "(5, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 15)\n",
      "(5, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 16)\n",
      "(5, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 17)\n",
      "(5, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 18)\n",
      "(5, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 19)\n",
      "(5, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 20)\n",
      "(5, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 21)\n",
      "(5, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 22)\n",
      "(5, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 23)\n",
      "(5, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 24)\n",
      "(5, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 25)\n",
      "(5, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 26)\n",
      "(5, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 27)\n",
      "(5, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 28)\n",
      "(5, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 29)\n",
      "(5, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 30)\n",
      "(5, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 31)\n",
      "(5, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 32)\n",
      "(5, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 33)\n",
      "(5, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 34)\n",
      "(5, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 35)\n",
      "(5, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 36)\n",
      "(5, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 37)\n",
      "(5, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 38)\n",
      "(5, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 39)\n",
      "(5, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 40)\n",
      "(5, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 41)\n",
      "(5, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 42)\n",
      "(5, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 43)\n",
      "(5, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 44)\n",
      "(5, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 45)\n",
      "(5, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 46)\n",
      "(5, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 47)\n",
      "(5, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 48)\n",
      "(5, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 1, 49)\n",
      "(5, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(5, 2)\n",
      "(5, 2, 0)\n",
      "(5, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 1)\n",
      "(5, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 2)\n",
      "(5, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 3)\n",
      "(5, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 4)\n",
      "(5, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 5)\n",
      "(5, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 6)\n",
      "(5, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 7)\n",
      "(5, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 8)\n",
      "(5, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 9)\n",
      "(5, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 10)\n",
      "(5, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 11)\n",
      "(5, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 12)\n",
      "(5, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 13)\n",
      "(5, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 14)\n",
      "(5, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 15)\n",
      "(5, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 16)\n",
      "(5, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 17)\n",
      "(5, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 18)\n",
      "(5, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 19)\n",
      "(5, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 20)\n",
      "(5, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 21)\n",
      "(5, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 22)\n",
      "(5, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 23)\n",
      "(5, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 24)\n",
      "(5, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 25)\n",
      "(5, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 26)\n",
      "(5, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 27)\n",
      "(5, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 28)\n",
      "(5, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 29)\n",
      "(5, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 30)\n",
      "(5, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 31)\n",
      "(5, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 32)\n",
      "(5, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 33)\n",
      "(5, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 34)\n",
      "(5, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 35)\n",
      "(5, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 36)\n",
      "(5, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 37)\n",
      "(5, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 38)\n",
      "(5, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 39)\n",
      "(5, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 40)\n",
      "(5, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 41)\n",
      "(5, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 42)\n",
      "(5, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 43)\n",
      "(5, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 44)\n",
      "(5, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 45)\n",
      "(5, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 46)\n",
      "(5, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 47)\n",
      "(5, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 48)\n",
      "(5, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 2, 49)\n",
      "(5, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(5, 3)\n",
      "(5, 3, 0)\n",
      "(5, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 1)\n",
      "(5, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 2)\n",
      "(5, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 3)\n",
      "(5, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 4)\n",
      "(5, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 5)\n",
      "(5, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 6)\n",
      "(5, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 7)\n",
      "(5, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 8)\n",
      "(5, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 9)\n",
      "(5, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 10)\n",
      "(5, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 11)\n",
      "(5, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 12)\n",
      "(5, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 13)\n",
      "(5, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 14)\n",
      "(5, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 15)\n",
      "(5, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 16)\n",
      "(5, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 17)\n",
      "(5, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 18)\n",
      "(5, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 19)\n",
      "(5, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(5, 3, 20)\n",
      "(5, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 21)\n",
      "(5, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 22)\n",
      "(5, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 23)\n",
      "(5, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 24)\n",
      "(5, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 25)\n",
      "(5, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(5, 3, 26)\n",
      "(5, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 27)\n",
      "(5, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 28)\n",
      "(5, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 29)\n",
      "(5, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 30)\n",
      "(5, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 31)\n",
      "(5, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 32)\n",
      "(5, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 33)\n",
      "(5, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 34)\n",
      "(5, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 35)\n",
      "(5, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 36)\n",
      "(5, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 37)\n",
      "(5, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(5, 3, 38)\n",
      "(5, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 39)\n",
      "(5, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 40)\n",
      "(5, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 41)\n",
      "(5, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 42)\n",
      "(5, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 43)\n",
      "(5, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 44)\n",
      "(5, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 45)\n",
      "(5, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 46)\n",
      "(5, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 47)\n",
      "(5, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 48)\n",
      "(5, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 3, 49)\n",
      "(5, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(5, 4)\n",
      "(5, 4, 0)\n",
      "(5, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:34:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:34:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 1)\n",
      "(5, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:35:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:35:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 2)\n",
      "(5, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:35:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 3)\n",
      "(5, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:36:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:36:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 4)\n",
      "(5, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:36:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:36:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 5)\n",
      "(5, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:36:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:36:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 6)\n",
      "(5, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:37:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 7)\n",
      "(5, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:37:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:37:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 8)\n",
      "(5, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:37:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:37:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 9)\n",
      "(5, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:38:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:38:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 10)\n",
      "(5, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:38:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:38:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 11)\n",
      "(5, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:38:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:38:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 12)\n",
      "(5, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:38:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:38:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 13)\n",
      "(5, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:39:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:39:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 14)\n",
      "(5, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:39:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:39:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 15)\n",
      "(5, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:40:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:40:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 16)\n",
      "(5, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 17)\n",
      "(5, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:40:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:40:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 18)\n",
      "(5, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:41:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 19)\n",
      "(5, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:41:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:41:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 20)\n",
      "(5, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:41:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:41:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 21)\n",
      "(5, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:41:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:41:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 22)\n",
      "(5, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:41:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:41:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 23)\n",
      "(5, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:42:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:42:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 24)\n",
      "(5, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:42:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:42:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 25)\n",
      "(5, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:43:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:43:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 26)\n",
      "(5, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:44:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:44:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 27)\n",
      "(5, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:44:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:44:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 28)\n",
      "(5, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:44:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:44:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 29)\n",
      "(5, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:44:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:44:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 30)\n",
      "(5, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:45:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:45:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 31)\n",
      "(5, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:45:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:45:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 32)\n",
      "(5, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:46:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 33)\n",
      "(5, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:46:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 34)\n",
      "(5, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:46:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 35)\n",
      "(5, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:46:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:46:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 36)\n",
      "(5, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:47:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:47:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 37)\n",
      "(5, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:47:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:47:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 38)\n",
      "(5, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:47:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:47:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 39)\n",
      "(5, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:48:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:48:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 40)\n",
      "(5, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:48:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:48:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 41)\n",
      "(5, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:48:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:48:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 42)\n",
      "(5, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 43)\n",
      "(5, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:49:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 44)\n",
      "(5, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:49:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:49:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 45)\n",
      "(5, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:49:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 46)\n",
      "(5, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:50:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:50:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 47)\n",
      "(5, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:50:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:50:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 48)\n",
      "(5, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 4, 49)\n",
      "(5, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[19:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:50:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(5, 5)\n",
      "(5, 5, 0)\n",
      "(5, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 1)\n",
      "(5, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 2)\n",
      "(5, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 3)\n",
      "(5, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 4)\n",
      "(5, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5)\n",
      "(5, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 6)\n",
      "(5, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 7)\n",
      "(5, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 8)\n",
      "(5, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 9)\n",
      "(5, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 10)\n",
      "(5, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 11)\n",
      "(5, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 12)\n",
      "(5, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 13)\n",
      "(5, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 14)\n",
      "(5, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 15)\n",
      "(5, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 16)\n",
      "(5, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 17)\n",
      "(5, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 18)\n",
      "(5, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 19)\n",
      "(5, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 20)\n",
      "(5, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 21)\n",
      "(5, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 22)\n",
      "(5, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 23)\n",
      "(5, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 24)\n",
      "(5, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 25)\n",
      "(5, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 26)\n",
      "(5, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 27)\n",
      "(5, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 28)\n",
      "(5, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 29)\n",
      "(5, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 30)\n",
      "(5, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 31)\n",
      "(5, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 32)\n",
      "(5, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 33)\n",
      "(5, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 34)\n",
      "(5, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 35)\n",
      "(5, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 36)\n",
      "(5, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 37)\n",
      "(5, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 38)\n",
      "(5, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 39)\n",
      "(5, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 40)\n",
      "(5, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 41)\n",
      "(5, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 42)\n",
      "(5, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 43)\n",
      "(5, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 44)\n",
      "(5, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 45)\n",
      "(5, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 46)\n",
      "(5, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 47)\n",
      "(5, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 48)\n",
      "(5, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 5, 49)\n",
      "(5, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(5, 6)\n",
      "(5, 6, 0)\n",
      "(5, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 1)\n",
      "(5, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 2)\n",
      "(5, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 3)\n",
      "(5, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 4)\n",
      "(5, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 5)\n",
      "(5, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 6)\n",
      "(5, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 7)\n",
      "(5, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 8)\n",
      "(5, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 9)\n",
      "(5, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 10)\n",
      "(5, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 11)\n",
      "(5, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 12)\n",
      "(5, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 13)\n",
      "(5, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 14)\n",
      "(5, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 15)\n",
      "(5, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 16)\n",
      "(5, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 17)\n",
      "(5, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 18)\n",
      "(5, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 19)\n",
      "(5, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 20)\n",
      "(5, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 21)\n",
      "(5, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 22)\n",
      "(5, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 23)\n",
      "(5, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 24)\n",
      "(5, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 25)\n",
      "(5, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 26)\n",
      "(5, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 27)\n",
      "(5, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 28)\n",
      "(5, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 29)\n",
      "(5, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 30)\n",
      "(5, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 31)\n",
      "(5, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 32)\n",
      "(5, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 33)\n",
      "(5, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 34)\n",
      "(5, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 35)\n",
      "(5, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 36)\n",
      "(5, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 37)\n",
      "(5, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 38)\n",
      "(5, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 39)\n",
      "(5, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 40)\n",
      "(5, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 41)\n",
      "(5, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 42)\n",
      "(5, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 43)\n",
      "(5, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 44)\n",
      "(5, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 45)\n",
      "(5, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 46)\n",
      "(5, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 47)\n",
      "(5, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 48)\n",
      "(5, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 49)\n",
      "(5, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-06-01\n",
      "6\n",
      "(6, 0)\n",
      "(6, 0, 0)\n",
      "(6, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:   23.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 1)\n",
      "(6, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 2)\n",
      "(6, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 3)\n",
      "(6, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 4)\n",
      "(6, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   39.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 5)\n",
      "(6, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   57.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 6)\n",
      "(6, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    8.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 7)\n",
      "(6, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 8)\n",
      "(6, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 9)\n",
      "(6, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   44.2s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   57.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 10)\n",
      "(6, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   22.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 11)\n",
      "(6, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 12)\n",
      "(6, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 13)\n",
      "(6, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   41.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 14)\n",
      "(6, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 15)\n",
      "(6, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 16)\n",
      "(6, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 17)\n",
      "(6, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:   17.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 18)\n",
      "(6, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 19)\n",
      "(6, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 20)\n",
      "(6, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 21)\n",
      "(6, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 22)\n",
      "(6, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   57.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 23)\n",
      "(6, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:   49.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 24)\n",
      "(6, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:   24.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 25)\n",
      "(6, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:   14.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 26)\n",
      "(6, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:   47.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 27)\n",
      "(6, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   34.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 28)\n",
      "(6, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 29)\n",
      "(6, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 30)\n",
      "(6, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 31)\n",
      "(6, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:   16.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 32)\n",
      "(6, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:   20.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 33)\n",
      "(6, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   27.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 34)\n",
      "(6, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 35)\n",
      "(6, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:   43.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 36)\n",
      "(6, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 37)\n",
      "(6, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:   25.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 38)\n",
      "(6, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 39)\n",
      "(6, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   47.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 40)\n",
      "(6, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 41)\n",
      "(6, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 42)\n",
      "(6, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 43)\n",
      "(6, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:   39.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 44)\n",
      "(6, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 45)\n",
      "(6, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:   39.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 46)\n",
      "(6, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 47)\n",
      "(6, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 48)\n",
      "(6, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   51.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 49)\n",
      "(6, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n",
      "(6, 1, 0)\n",
      "(6, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 1)\n",
      "(6, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 2)\n",
      "(6, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 3)\n",
      "(6, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 4)\n",
      "(6, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 5)\n",
      "(6, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 6)\n",
      "(6, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 7)\n",
      "(6, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 8)\n",
      "(6, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 9)\n",
      "(6, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 10)\n",
      "(6, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 11)\n",
      "(6, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 12)\n",
      "(6, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 13)\n",
      "(6, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 14)\n",
      "(6, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 15)\n",
      "(6, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 16)\n",
      "(6, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 17)\n",
      "(6, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 18)\n",
      "(6, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 19)\n",
      "(6, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 20)\n",
      "(6, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 21)\n",
      "(6, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 22)\n",
      "(6, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 23)\n",
      "(6, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 24)\n",
      "(6, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 25)\n",
      "(6, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 26)\n",
      "(6, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 27)\n",
      "(6, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 28)\n",
      "(6, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 29)\n",
      "(6, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 30)\n",
      "(6, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 31)\n",
      "(6, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 32)\n",
      "(6, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 33)\n",
      "(6, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 34)\n",
      "(6, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 35)\n",
      "(6, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 36)\n",
      "(6, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 37)\n",
      "(6, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 38)\n",
      "(6, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 39)\n",
      "(6, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 40)\n",
      "(6, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 41)\n",
      "(6, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 42)\n",
      "(6, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 43)\n",
      "(6, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 44)\n",
      "(6, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 45)\n",
      "(6, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 46)\n",
      "(6, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 47)\n",
      "(6, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 48)\n",
      "(6, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 1, 49)\n",
      "(6, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(6, 2)\n",
      "(6, 2, 0)\n",
      "(6, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 1)\n",
      "(6, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 2)\n",
      "(6, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 3)\n",
      "(6, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 4)\n",
      "(6, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 5)\n",
      "(6, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 6)\n",
      "(6, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 7)\n",
      "(6, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 8)\n",
      "(6, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 9)\n",
      "(6, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 10)\n",
      "(6, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 11)\n",
      "(6, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 12)\n",
      "(6, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 13)\n",
      "(6, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 14)\n",
      "(6, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 15)\n",
      "(6, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 16)\n",
      "(6, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 17)\n",
      "(6, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 18)\n",
      "(6, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 19)\n",
      "(6, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 20)\n",
      "(6, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 21)\n",
      "(6, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 22)\n",
      "(6, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 23)\n",
      "(6, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 24)\n",
      "(6, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 25)\n",
      "(6, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 26)\n",
      "(6, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 27)\n",
      "(6, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 28)\n",
      "(6, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 29)\n",
      "(6, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 30)\n",
      "(6, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 31)\n",
      "(6, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 32)\n",
      "(6, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 33)\n",
      "(6, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 34)\n",
      "(6, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 35)\n",
      "(6, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 36)\n",
      "(6, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 37)\n",
      "(6, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 38)\n",
      "(6, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 39)\n",
      "(6, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 40)\n",
      "(6, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 41)\n",
      "(6, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 42)\n",
      "(6, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 43)\n",
      "(6, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 44)\n",
      "(6, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 45)\n",
      "(6, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 46)\n",
      "(6, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 47)\n",
      "(6, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 48)\n",
      "(6, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 2, 49)\n",
      "(6, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(6, 3)\n",
      "(6, 3, 0)\n",
      "(6, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 1)\n",
      "(6, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 2)\n",
      "(6, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 3)\n",
      "(6, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 4)\n",
      "(6, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 5)\n",
      "(6, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 6)\n",
      "(6, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 7)\n",
      "(6, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 8)\n",
      "(6, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 9)\n",
      "(6, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 10)\n",
      "(6, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 11)\n",
      "(6, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 12)\n",
      "(6, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 13)\n",
      "(6, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 14)\n",
      "(6, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 15)\n",
      "(6, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 16)\n",
      "(6, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 17)\n",
      "(6, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 18)\n",
      "(6, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 19)\n",
      "(6, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(6, 3, 20)\n",
      "(6, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 21)\n",
      "(6, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 22)\n",
      "(6, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 23)\n",
      "(6, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 24)\n",
      "(6, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 25)\n",
      "(6, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(6, 3, 26)\n",
      "(6, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 27)\n",
      "(6, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 28)\n",
      "(6, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 29)\n",
      "(6, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 30)\n",
      "(6, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 31)\n",
      "(6, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 32)\n",
      "(6, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 33)\n",
      "(6, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 34)\n",
      "(6, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 35)\n",
      "(6, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 36)\n",
      "(6, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 37)\n",
      "(6, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(6, 3, 38)\n",
      "(6, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 39)\n",
      "(6, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 40)\n",
      "(6, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 41)\n",
      "(6, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 42)\n",
      "(6, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 43)\n",
      "(6, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 44)\n",
      "(6, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 45)\n",
      "(6, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 46)\n",
      "(6, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 47)\n",
      "(6, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 48)\n",
      "(6, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 3, 49)\n",
      "(6, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(6, 4)\n",
      "(6, 4, 0)\n",
      "(6, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:08:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 1)\n",
      "(6, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:08:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 2)\n",
      "(6, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:09:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 3)\n",
      "(6, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:09:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:09:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 4)\n",
      "(6, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:09:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 5)\n",
      "(6, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:10:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 6)\n",
      "(6, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:10:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:10:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 7)\n",
      "(6, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:10:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:10:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 8)\n",
      "(6, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:11:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 9)\n",
      "(6, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:11:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:11:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 10)\n",
      "(6, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:12:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:12:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 11)\n",
      "(6, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:12:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 12)\n",
      "(6, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:12:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 13)\n",
      "(6, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:13:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:13:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 14)\n",
      "(6, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:13:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 15)\n",
      "(6, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:14:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:14:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 16)\n",
      "(6, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 17)\n",
      "(6, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:14:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:14:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 18)\n",
      "(6, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:15:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:15:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 19)\n",
      "(6, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:15:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:15:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 20)\n",
      "(6, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:15:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:15:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 21)\n",
      "(6, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:15:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:15:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 22)\n",
      "(6, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:16:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:16:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 23)\n",
      "(6, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:16:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 24)\n",
      "(6, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:17:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:17:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 25)\n",
      "(6, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:18:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:18:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 26)\n",
      "(6, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:19:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:19:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 27)\n",
      "(6, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:19:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:19:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 28)\n",
      "(6, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:19:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:19:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 29)\n",
      "(6, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 30)\n",
      "(6, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:20:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:20:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 31)\n",
      "(6, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:20:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:20:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 32)\n",
      "(6, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:21:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:21:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 33)\n",
      "(6, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:21:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:21:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 34)\n",
      "(6, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:21:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 35)\n",
      "(6, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:22:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:22:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 36)\n",
      "(6, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:22:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:22:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 37)\n",
      "(6, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:23:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:23:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 38)\n",
      "(6, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 39)\n",
      "(6, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:23:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:23:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 40)\n",
      "(6, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:24:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 41)\n",
      "(6, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:24:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 42)\n",
      "(6, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:24:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 43)\n",
      "(6, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:24:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:24:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 44)\n",
      "(6, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:25:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:25:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 45)\n",
      "(6, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:25:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:25:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 46)\n",
      "(6, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:25:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:25:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 47)\n",
      "(6, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 48)\n",
      "(6, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:26:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:26:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 4, 49)\n",
      "(6, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[23:26:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:26:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(6, 5)\n",
      "(6, 5, 0)\n",
      "(6, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 1)\n",
      "(6, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 2)\n",
      "(6, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 3)\n",
      "(6, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 4)\n",
      "(6, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 5)\n",
      "(6, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 6)\n",
      "(6, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 7)\n",
      "(6, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 8)\n",
      "(6, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 9)\n",
      "(6, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 10)\n",
      "(6, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 11)\n",
      "(6, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 12)\n",
      "(6, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 13)\n",
      "(6, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 14)\n",
      "(6, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 15)\n",
      "(6, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 16)\n",
      "(6, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 17)\n",
      "(6, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 18)\n",
      "(6, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 19)\n",
      "(6, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 20)\n",
      "(6, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 21)\n",
      "(6, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 22)\n",
      "(6, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 23)\n",
      "(6, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 24)\n",
      "(6, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 25)\n",
      "(6, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 26)\n",
      "(6, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 27)\n",
      "(6, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 28)\n",
      "(6, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 29)\n",
      "(6, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 30)\n",
      "(6, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 31)\n",
      "(6, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 32)\n",
      "(6, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 33)\n",
      "(6, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 34)\n",
      "(6, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 35)\n",
      "(6, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 36)\n",
      "(6, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 37)\n",
      "(6, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 38)\n",
      "(6, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 39)\n",
      "(6, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5, 40)\n",
      "(6, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 41)\n",
      "(6, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 42)\n",
      "(6, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 43)\n",
      "(6, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 44)\n",
      "(6, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 45)\n",
      "(6, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 46)\n",
      "(6, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 47)\n",
      "(6, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 48)\n",
      "(6, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 5, 49)\n",
      "(6, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(6, 6)\n",
      "(6, 6, 0)\n",
      "(6, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 1)\n",
      "(6, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 2)\n",
      "(6, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 3)\n",
      "(6, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 4)\n",
      "(6, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 5)\n",
      "(6, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 6)\n",
      "(6, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 7)\n",
      "(6, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 8)\n",
      "(6, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 9)\n",
      "(6, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 10)\n",
      "(6, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 11)\n",
      "(6, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 12)\n",
      "(6, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 13)\n",
      "(6, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 14)\n",
      "(6, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 15)\n",
      "(6, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 16)\n",
      "(6, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 17)\n",
      "(6, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 18)\n",
      "(6, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 19)\n",
      "(6, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 20)\n",
      "(6, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 21)\n",
      "(6, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 22)\n",
      "(6, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 23)\n",
      "(6, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 24)\n",
      "(6, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 25)\n",
      "(6, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 26)\n",
      "(6, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 27)\n",
      "(6, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 28)\n",
      "(6, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 29)\n",
      "(6, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 30)\n",
      "(6, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 31)\n",
      "(6, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 32)\n",
      "(6, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 33)\n",
      "(6, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 34)\n",
      "(6, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 35)\n",
      "(6, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 36)\n",
      "(6, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 37)\n",
      "(6, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 38)\n",
      "(6, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 39)\n",
      "(6, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 40)\n",
      "(6, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 41)\n",
      "(6, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 42)\n",
      "(6, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 43)\n",
      "(6, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 44)\n",
      "(6, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 45)\n",
      "(6, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 46)\n",
      "(6, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 47)\n",
      "(6, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 48)\n",
      "(6, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 49)\n",
      "(6, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-07-01\n",
      "7\n",
      "(7, 0)\n",
      "(7, 0, 0)\n",
      "(7, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:   22.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 1)\n",
      "(7, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 2)\n",
      "(7, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   59.3s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 3)\n",
      "(7, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 4)\n",
      "(7, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   37.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 5)\n",
      "(7, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 6)\n",
      "(7, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    8.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 7)\n",
      "(7, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 8)\n",
      "(7, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:   56.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 9)\n",
      "(7, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   42.4s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   54.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 10)\n",
      "(7, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   21.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 11)\n",
      "(7, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 12)\n",
      "(7, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   54.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 13)\n",
      "(7, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 14)\n",
      "(7, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 15)\n",
      "(7, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  3.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 16)\n",
      "(7, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 17)\n",
      "(7, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:   17.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 18)\n",
      "(7, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 19)\n",
      "(7, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 20)\n",
      "(7, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 21)\n",
      "(7, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 22)\n",
      "(7, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   55.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 23)\n",
      "(7, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:   51.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 24)\n",
      "(7, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:   23.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 25)\n",
      "(7, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 26)\n",
      "(7, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 27)\n",
      "(7, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   40.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 28)\n",
      "(7, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 29)\n",
      "(7, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 30)\n",
      "(7, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 31)\n",
      "(7, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 32)\n",
      "(7, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:   24.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 33)\n",
      "(7, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   29.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 34)\n",
      "(7, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 35)\n",
      "(7, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:   42.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 36)\n",
      "(7, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 37)\n",
      "(7, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:   28.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 38)\n",
      "(7, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 39)\n",
      "(7, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 40)\n",
      "(7, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   46.9s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 41)\n",
      "(7, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 42)\n",
      "(7, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 43)\n",
      "(7, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:   41.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 44)\n",
      "(7, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    7.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 45)\n",
      "(7, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 46)\n",
      "(7, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   31.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:  4.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 47)\n",
      "(7, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 48)\n",
      "(7, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 0, 49)\n",
      "(7, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "(7, 1, 0)\n",
      "(7, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 1)\n",
      "(7, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 2)\n",
      "(7, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 3)\n",
      "(7, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 4)\n",
      "(7, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 5)\n",
      "(7, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 6)\n",
      "(7, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 7)\n",
      "(7, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 8)\n",
      "(7, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 9)\n",
      "(7, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 10)\n",
      "(7, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 11)\n",
      "(7, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 12)\n",
      "(7, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 13)\n",
      "(7, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 14)\n",
      "(7, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 15)\n",
      "(7, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 16)\n",
      "(7, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 17)\n",
      "(7, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 18)\n",
      "(7, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 19)\n",
      "(7, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 20)\n",
      "(7, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 21)\n",
      "(7, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 22)\n",
      "(7, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 23)\n",
      "(7, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 24)\n",
      "(7, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 25)\n",
      "(7, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 26)\n",
      "(7, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 27)\n",
      "(7, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 28)\n",
      "(7, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 29)\n",
      "(7, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 30)\n",
      "(7, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 31)\n",
      "(7, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 32)\n",
      "(7, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 33)\n",
      "(7, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 34)\n",
      "(7, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 35)\n",
      "(7, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 36)\n",
      "(7, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 37)\n",
      "(7, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 38)\n",
      "(7, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 39)\n",
      "(7, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 40)\n",
      "(7, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 41)\n",
      "(7, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 42)\n",
      "(7, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 43)\n",
      "(7, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 44)\n",
      "(7, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 45)\n",
      "(7, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 46)\n",
      "(7, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 47)\n",
      "(7, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 48)\n",
      "(7, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 1, 49)\n",
      "(7, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(7, 2)\n",
      "(7, 2, 0)\n",
      "(7, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 1)\n",
      "(7, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 2)\n",
      "(7, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 3)\n",
      "(7, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 4)\n",
      "(7, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 5)\n",
      "(7, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 6)\n",
      "(7, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 7)\n",
      "(7, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 8)\n",
      "(7, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 9)\n",
      "(7, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 10)\n",
      "(7, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 11)\n",
      "(7, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 12)\n",
      "(7, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 13)\n",
      "(7, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 14)\n",
      "(7, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 15)\n",
      "(7, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 16)\n",
      "(7, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 17)\n",
      "(7, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 18)\n",
      "(7, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 19)\n",
      "(7, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 20)\n",
      "(7, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 21)\n",
      "(7, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 22)\n",
      "(7, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 23)\n",
      "(7, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 24)\n",
      "(7, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 25)\n",
      "(7, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 26)\n",
      "(7, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 27)\n",
      "(7, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 28)\n",
      "(7, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 29)\n",
      "(7, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 30)\n",
      "(7, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 31)\n",
      "(7, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 32)\n",
      "(7, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 33)\n",
      "(7, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 34)\n",
      "(7, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 35)\n",
      "(7, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 36)\n",
      "(7, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 37)\n",
      "(7, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 38)\n",
      "(7, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 39)\n",
      "(7, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 40)\n",
      "(7, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 41)\n",
      "(7, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 42)\n",
      "(7, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 43)\n",
      "(7, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 44)\n",
      "(7, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 45)\n",
      "(7, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 46)\n",
      "(7, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 47)\n",
      "(7, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 48)\n",
      "(7, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 2, 49)\n",
      "(7, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(7, 3)\n",
      "(7, 3, 0)\n",
      "(7, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 1)\n",
      "(7, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 2)\n",
      "(7, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 3)\n",
      "(7, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 4)\n",
      "(7, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 5)\n",
      "(7, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 6)\n",
      "(7, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 7)\n",
      "(7, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 8)\n",
      "(7, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 9)\n",
      "(7, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 10)\n",
      "(7, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 11)\n",
      "(7, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 12)\n",
      "(7, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 13)\n",
      "(7, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 14)\n",
      "(7, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 15)\n",
      "(7, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 16)\n",
      "(7, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 17)\n",
      "(7, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 18)\n",
      "(7, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 19)\n",
      "(7, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(7, 3, 20)\n",
      "(7, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 21)\n",
      "(7, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 22)\n",
      "(7, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 23)\n",
      "(7, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 24)\n",
      "(7, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 25)\n",
      "(7, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(7, 3, 26)\n",
      "(7, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 27)\n",
      "(7, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 28)\n",
      "(7, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 29)\n",
      "(7, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 30)\n",
      "(7, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 31)\n",
      "(7, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 32)\n",
      "(7, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 33)\n",
      "(7, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 34)\n",
      "(7, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 35)\n",
      "(7, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 36)\n",
      "(7, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 37)\n",
      "(7, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(7, 3, 38)\n",
      "(7, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 39)\n",
      "(7, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 40)\n",
      "(7, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 41)\n",
      "(7, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 42)\n",
      "(7, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 43)\n",
      "(7, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 44)\n",
      "(7, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 45)\n",
      "(7, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 46)\n",
      "(7, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 47)\n",
      "(7, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 48)\n",
      "(7, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 3, 49)\n",
      "(7, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(7, 4)\n",
      "(7, 4, 0)\n",
      "(7, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:58:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:58:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 1)\n",
      "(7, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 2)\n",
      "(7, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:59:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:59:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 3)\n",
      "(7, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:59:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:59:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 4)\n",
      "(7, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:59:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:59:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 5)\n",
      "(7, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:00:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:00:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 6)\n",
      "(7, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:00:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:00:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 7)\n",
      "(7, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:01:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:01:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 8)\n",
      "(7, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:01:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 9)\n",
      "(7, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:02:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:02:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 10)\n",
      "(7, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:02:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:02:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 11)\n",
      "(7, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:02:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:02:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 12)\n",
      "(7, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:03:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 13)\n",
      "(7, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:04:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:04:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 14)\n",
      "(7, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 15)\n",
      "(7, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:04:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 16)\n",
      "(7, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:05:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 17)\n",
      "(7, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:05:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 18)\n",
      "(7, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:06:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:06:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 19)\n",
      "(7, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:06:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:06:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 20)\n",
      "(7, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:06:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:06:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 21)\n",
      "(7, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:06:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 22)\n",
      "(7, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:06:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 23)\n",
      "(7, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:07:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:07:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 24)\n",
      "(7, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 25)\n",
      "(7, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:09:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 26)\n",
      "(7, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:10:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 27)\n",
      "(7, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:10:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 28)\n",
      "(7, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:10:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 29)\n",
      "(7, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:10:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 30)\n",
      "(7, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:11:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:11:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 31)\n",
      "(7, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:11:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:11:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 32)\n",
      "(7, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 33)\n",
      "(7, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:12:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:12:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 34)\n",
      "(7, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:12:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 35)\n",
      "(7, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:12:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:12:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 36)\n",
      "(7, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:13:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:13:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 37)\n",
      "(7, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:14:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:14:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 38)\n",
      "(7, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:14:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:14:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 39)\n",
      "(7, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:14:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:14:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 40)\n",
      "(7, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:15:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:15:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 41)\n",
      "(7, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:15:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:15:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 42)\n",
      "(7, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 43)\n",
      "(7, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:15:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:15:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 44)\n",
      "(7, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 45)\n",
      "(7, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:16:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 46)\n",
      "(7, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 47)\n",
      "(7, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:16:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 48)\n",
      "(7, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:17:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:17:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 4, 49)\n",
      "(7, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:17:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:17:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(7, 5)\n",
      "(7, 5, 0)\n",
      "(7, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 1)\n",
      "(7, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 2)\n",
      "(7, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 3)\n",
      "(7, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 4)\n",
      "(7, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 5)\n",
      "(7, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 6)\n",
      "(7, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 7)\n",
      "(7, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 8)\n",
      "(7, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 9)\n",
      "(7, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 10)\n",
      "(7, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 11)\n",
      "(7, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 12)\n",
      "(7, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5, 13)\n",
      "(7, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 14)\n",
      "(7, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 15)\n",
      "(7, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 16)\n",
      "(7, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 17)\n",
      "(7, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 18)\n",
      "(7, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 19)\n",
      "(7, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 20)\n",
      "(7, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 21)\n",
      "(7, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 22)\n",
      "(7, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 23)\n",
      "(7, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 24)\n",
      "(7, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 25)\n",
      "(7, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 26)\n",
      "(7, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 27)\n",
      "(7, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 28)\n",
      "(7, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 29)\n",
      "(7, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5, 30)\n",
      "(7, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5, 31)\n",
      "(7, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 32)\n",
      "(7, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 33)\n",
      "(7, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 34)\n",
      "(7, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 35)\n",
      "(7, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 36)\n",
      "(7, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 37)\n",
      "(7, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5, 38)\n",
      "(7, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 39)\n",
      "(7, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5, 40)\n",
      "(7, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 41)\n",
      "(7, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 42)\n",
      "(7, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 43)\n",
      "(7, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 44)\n",
      "(7, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 45)\n",
      "(7, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 46)\n",
      "(7, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 47)\n",
      "(7, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 48)\n",
      "(7, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 5, 49)\n",
      "(7, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(7, 6)\n",
      "(7, 6, 0)\n",
      "(7, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 1)\n",
      "(7, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 2)\n",
      "(7, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 3)\n",
      "(7, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 4)\n",
      "(7, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 5)\n",
      "(7, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 6)\n",
      "(7, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 7)\n",
      "(7, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 8)\n",
      "(7, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 9)\n",
      "(7, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 10)\n",
      "(7, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 11)\n",
      "(7, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 12)\n",
      "(7, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 13)\n",
      "(7, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 14)\n",
      "(7, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 15)\n",
      "(7, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 16)\n",
      "(7, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 17)\n",
      "(7, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 18)\n",
      "(7, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 19)\n",
      "(7, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 20)\n",
      "(7, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 21)\n",
      "(7, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 22)\n",
      "(7, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 23)\n",
      "(7, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 24)\n",
      "(7, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 25)\n",
      "(7, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 26)\n",
      "(7, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 27)\n",
      "(7, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 28)\n",
      "(7, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 29)\n",
      "(7, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 30)\n",
      "(7, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 31)\n",
      "(7, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 32)\n",
      "(7, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 33)\n",
      "(7, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 34)\n",
      "(7, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 35)\n",
      "(7, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 36)\n",
      "(7, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 37)\n",
      "(7, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 38)\n",
      "(7, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 39)\n",
      "(7, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 40)\n",
      "(7, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 41)\n",
      "(7, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 42)\n",
      "(7, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 43)\n",
      "(7, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 44)\n",
      "(7, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 45)\n",
      "(7, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 46)\n",
      "(7, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 47)\n",
      "(7, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 48)\n",
      "(7, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 6, 49)\n",
      "(7, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-08-01\n",
      "8\n",
      "(8, 0)\n",
      "(8, 0, 0)\n",
      "(8, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:   30.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 1)\n",
      "(8, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   48.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 2)\n",
      "(8, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 3)\n",
      "(8, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 4)\n",
      "(8, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   48.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 5)\n",
      "(8, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 6)\n",
      "(8, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 7)\n",
      "(8, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:   18.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 8)\n",
      "(8, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 9)\n",
      "(8, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 10)\n",
      "(8, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   27.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 11)\n",
      "(8, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 12)\n",
      "(8, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 13)\n",
      "(8, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:  3.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 14)\n",
      "(8, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 15)\n",
      "(8, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 16)\n",
      "(8, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 17)\n",
      "(8, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:   24.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 18)\n",
      "(8, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 19)\n",
      "(8, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 20)\n",
      "(8, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 21)\n",
      "(8, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 22)\n",
      "(8, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 23)\n",
      "(8, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:   59.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 24)\n",
      "(8, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:   34.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 25)\n",
      "(8, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 26)\n",
      "(8, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 27)\n",
      "(8, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 28)\n",
      "(8, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   57.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 29)\n",
      "(8, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 30)\n",
      "(8, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 31)\n",
      "(8, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:   25.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 32)\n",
      "(8, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:   26.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 33)\n",
      "(8, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:   35.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 34)\n",
      "(8, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:  3.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 35)\n",
      "(8, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 36)\n",
      "(8, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 37)\n",
      "(8, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:   35.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 38)\n",
      "(8, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 39)\n",
      "(8, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 40)\n",
      "(8, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 41)\n",
      "(8, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 42)\n",
      "(8, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 43)\n",
      "(8, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:   46.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 44)\n",
      "(8, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 45)\n",
      "(8, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:   49.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 46)\n",
      "(8, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   56.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 47)\n",
      "(8, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 48)\n",
      "(8, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:  4.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    7.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 0, 49)\n",
      "(8, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1)\n",
      "(8, 1, 0)\n",
      "(8, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 1)\n",
      "(8, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 2)\n",
      "(8, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 3)\n",
      "(8, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 4)\n",
      "(8, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 5)\n",
      "(8, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 6)\n",
      "(8, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 7)\n",
      "(8, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 8)\n",
      "(8, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 9)\n",
      "(8, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 10)\n",
      "(8, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 11)\n",
      "(8, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 12)\n",
      "(8, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 13)\n",
      "(8, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 14)\n",
      "(8, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 15)\n",
      "(8, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 16)\n",
      "(8, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 17)\n",
      "(8, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 18)\n",
      "(8, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 19)\n",
      "(8, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 20)\n",
      "(8, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 21)\n",
      "(8, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 22)\n",
      "(8, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 23)\n",
      "(8, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 24)\n",
      "(8, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 25)\n",
      "(8, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 26)\n",
      "(8, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 27)\n",
      "(8, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 28)\n",
      "(8, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 29)\n",
      "(8, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 30)\n",
      "(8, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 31)\n",
      "(8, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 32)\n",
      "(8, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 33)\n",
      "(8, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 34)\n",
      "(8, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 35)\n",
      "(8, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 36)\n",
      "(8, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 37)\n",
      "(8, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 38)\n",
      "(8, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 39)\n",
      "(8, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 40)\n",
      "(8, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 41)\n",
      "(8, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 42)\n",
      "(8, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 43)\n",
      "(8, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 44)\n",
      "(8, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 45)\n",
      "(8, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 46)\n",
      "(8, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 47)\n",
      "(8, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 48)\n",
      "(8, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 1, 49)\n",
      "(8, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(8, 2)\n",
      "(8, 2, 0)\n",
      "(8, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 1)\n",
      "(8, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 2)\n",
      "(8, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 3)\n",
      "(8, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 4)\n",
      "(8, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 5)\n",
      "(8, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 6)\n",
      "(8, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 7)\n",
      "(8, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 8)\n",
      "(8, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 9)\n",
      "(8, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 10)\n",
      "(8, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 11)\n",
      "(8, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 12)\n",
      "(8, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 13)\n",
      "(8, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 14)\n",
      "(8, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 15)\n",
      "(8, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 16)\n",
      "(8, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 17)\n",
      "(8, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 18)\n",
      "(8, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 19)\n",
      "(8, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 20)\n",
      "(8, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 21)\n",
      "(8, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 22)\n",
      "(8, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 23)\n",
      "(8, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 24)\n",
      "(8, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 25)\n",
      "(8, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 26)\n",
      "(8, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 27)\n",
      "(8, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 28)\n",
      "(8, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 29)\n",
      "(8, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 30)\n",
      "(8, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 31)\n",
      "(8, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 32)\n",
      "(8, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 33)\n",
      "(8, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 34)\n",
      "(8, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 35)\n",
      "(8, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 36)\n",
      "(8, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 37)\n",
      "(8, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 38)\n",
      "(8, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 39)\n",
      "(8, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 40)\n",
      "(8, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 41)\n",
      "(8, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 42)\n",
      "(8, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 43)\n",
      "(8, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 44)\n",
      "(8, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 45)\n",
      "(8, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 46)\n",
      "(8, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 47)\n",
      "(8, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 48)\n",
      "(8, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 2, 49)\n",
      "(8, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(8, 3)\n",
      "(8, 3, 0)\n",
      "(8, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 1)\n",
      "(8, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 2)\n",
      "(8, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 3)\n",
      "(8, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 4)\n",
      "(8, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 5)\n",
      "(8, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 6)\n",
      "(8, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 7)\n",
      "(8, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 8)\n",
      "(8, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 9)\n",
      "(8, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 10)\n",
      "(8, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 11)\n",
      "(8, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 12)\n",
      "(8, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 13)\n",
      "(8, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 14)\n",
      "(8, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 15)\n",
      "(8, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 16)\n",
      "(8, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 17)\n",
      "(8, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 18)\n",
      "(8, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 19)\n",
      "(8, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(8, 3, 20)\n",
      "(8, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 21)\n",
      "(8, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 22)\n",
      "(8, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 23)\n",
      "(8, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 24)\n",
      "(8, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 25)\n",
      "(8, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(8, 3, 26)\n",
      "(8, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 27)\n",
      "(8, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 28)\n",
      "(8, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 29)\n",
      "(8, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 30)\n",
      "(8, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 31)\n",
      "(8, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 32)\n",
      "(8, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 33)\n",
      "(8, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 34)\n",
      "(8, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 35)\n",
      "(8, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 36)\n",
      "(8, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 37)\n",
      "(8, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(8, 3, 38)\n",
      "(8, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 39)\n",
      "(8, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 40)\n",
      "(8, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 41)\n",
      "(8, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 42)\n",
      "(8, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 43)\n",
      "(8, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 44)\n",
      "(8, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 45)\n",
      "(8, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 46)\n",
      "(8, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 47)\n",
      "(8, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 48)\n",
      "(8, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 3, 49)\n",
      "(8, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(8, 4)\n",
      "(8, 4, 0)\n",
      "(8, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:20:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:20:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 1)\n",
      "(8, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:21:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:21:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 2)\n",
      "(8, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:21:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 3)\n",
      "(8, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 4)\n",
      "(8, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:22:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:22:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 5)\n",
      "(8, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:23:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 6)\n",
      "(8, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:23:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 7)\n",
      "(8, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:23:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:23:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 8)\n",
      "(8, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:24:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:24:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 9)\n",
      "(8, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:25:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:25:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 10)\n",
      "(8, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:25:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:25:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 11)\n",
      "(8, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:25:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:26:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 12)\n",
      "(8, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:26:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:26:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 13)\n",
      "(8, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:27:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:27:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 14)\n",
      "(8, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:27:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:27:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 15)\n",
      "(8, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 16)\n",
      "(8, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 17)\n",
      "(8, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 18)\n",
      "(8, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 19)\n",
      "(8, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:30:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 20)\n",
      "(8, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:30:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:30:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 21)\n",
      "(8, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:31:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:31:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 22)\n",
      "(8, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:31:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:31:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 23)\n",
      "(8, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:32:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:32:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 24)\n",
      "(8, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:32:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:32:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 25)\n",
      "(8, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:34:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:34:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 26)\n",
      "(8, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:35:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:35:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 27)\n",
      "(8, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:35:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:35:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 28)\n",
      "(8, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:35:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:35:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 29)\n",
      "(8, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:36:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:36:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 30)\n",
      "(8, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:36:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:36:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 31)\n",
      "(8, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:36:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 32)\n",
      "(8, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:37:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:37:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 33)\n",
      "(8, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:38:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:38:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 34)\n",
      "(8, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:38:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 35)\n",
      "(8, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:38:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:38:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 36)\n",
      "(8, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:39:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:39:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 37)\n",
      "(8, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:40:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:40:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 38)\n",
      "(8, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 39)\n",
      "(8, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:41:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:41:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 40)\n",
      "(8, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:41:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:41:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 41)\n",
      "(8, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:41:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:41:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 42)\n",
      "(8, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:42:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:42:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 43)\n",
      "(8, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:42:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:42:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 44)\n",
      "(8, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:43:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:43:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 45)\n",
      "(8, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:43:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:43:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 46)\n",
      "(8, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:43:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:43:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 47)\n",
      "(8, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:43:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:43:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 48)\n",
      "(8, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:44:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:44:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 4, 49)\n",
      "(8, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[05:44:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:44:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(8, 5)\n",
      "(8, 5, 0)\n",
      "(8, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 1)\n",
      "(8, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 2)\n",
      "(8, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 3)\n",
      "(8, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 4)\n",
      "(8, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 5)\n",
      "(8, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 6)\n",
      "(8, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 7)\n",
      "(8, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 8)\n",
      "(8, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 9)\n",
      "(8, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 10)\n",
      "(8, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 11)\n",
      "(8, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 12)\n",
      "(8, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 13)\n",
      "(8, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 14)\n",
      "(8, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 15)\n",
      "(8, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 16)\n",
      "(8, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 17)\n",
      "(8, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 18)\n",
      "(8, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 19)\n",
      "(8, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 20)\n",
      "(8, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 21)\n",
      "(8, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 22)\n",
      "(8, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 23)\n",
      "(8, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 24)\n",
      "(8, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 25)\n",
      "(8, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 26)\n",
      "(8, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 27)\n",
      "(8, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 28)\n",
      "(8, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 29)\n",
      "(8, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 30)\n",
      "(8, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 31)\n",
      "(8, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 32)\n",
      "(8, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 33)\n",
      "(8, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 34)\n",
      "(8, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 35)\n",
      "(8, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 36)\n",
      "(8, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 37)\n",
      "(8, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 38)\n",
      "(8, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 39)\n",
      "(8, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 5, 40)\n",
      "(8, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 41)\n",
      "(8, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 42)\n",
      "(8, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 43)\n",
      "(8, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 44)\n",
      "(8, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 45)\n",
      "(8, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 46)\n",
      "(8, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 47)\n",
      "(8, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 48)\n",
      "(8, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 5, 49)\n",
      "(8, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(8, 6)\n",
      "(8, 6, 0)\n",
      "(8, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 1)\n",
      "(8, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 2)\n",
      "(8, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 3)\n",
      "(8, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 4)\n",
      "(8, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 5)\n",
      "(8, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 6)\n",
      "(8, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 7)\n",
      "(8, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 8)\n",
      "(8, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 9)\n",
      "(8, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 10)\n",
      "(8, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 11)\n",
      "(8, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 12)\n",
      "(8, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 13)\n",
      "(8, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 14)\n",
      "(8, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 15)\n",
      "(8, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 16)\n",
      "(8, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 17)\n",
      "(8, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 18)\n",
      "(8, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 19)\n",
      "(8, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 20)\n",
      "(8, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 21)\n",
      "(8, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 22)\n",
      "(8, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 23)\n",
      "(8, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 24)\n",
      "(8, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 25)\n",
      "(8, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 26)\n",
      "(8, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 27)\n",
      "(8, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 28)\n",
      "(8, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 29)\n",
      "(8, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 30)\n",
      "(8, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 31)\n",
      "(8, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 32)\n",
      "(8, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 33)\n",
      "(8, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 34)\n",
      "(8, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 35)\n",
      "(8, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 36)\n",
      "(8, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 37)\n",
      "(8, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 38)\n",
      "(8, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 39)\n",
      "(8, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 40)\n",
      "(8, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 41)\n",
      "(8, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 42)\n",
      "(8, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 43)\n",
      "(8, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 44)\n",
      "(8, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 45)\n",
      "(8, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 46)\n",
      "(8, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 47)\n",
      "(8, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 48)\n",
      "(8, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 6, 49)\n",
      "(8, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-09-01\n",
      "9\n",
      "(9, 0)\n",
      "(9, 0, 0)\n",
      "(9, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:   37.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 1)\n",
      "(9, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 2)\n",
      "(9, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 3)\n",
      "(9, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 4)\n",
      "(9, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   47.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 5)\n",
      "(9, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 6)\n",
      "(9, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 7)\n",
      "(9, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:   21.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 0, 8)\n",
      "(9, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.1s\n"
     ]
    }
   ],
   "source": [
    "#loop through time split\n",
    "for t in range(time_frames.shape[0]):\n",
    "    date = time_frames.iloc[t].Start_Threshold\n",
    "    print(date)\n",
    "    print(t)\n",
    "    \n",
    "#     fold_data = data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ' )\n",
    "    \n",
    "#     X = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "#             .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "#     y = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "#             ['quickstart_label'].apply(int)\n",
    "    \n",
    "    fold_data = data.query(f' as_of_date <= \"{time_frames.iloc[t].End_Test}\" ' )\n",
    "    \n",
    "    X = fold_data.query(f' as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "            .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "    y = fold_data.query(f'as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "            ['quickstart_label'].apply(int)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    X_k_test = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "    X_k_test_dates = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            ['as_of_date']\n",
    "    y_k_test = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            ['quickstart_label'].apply(int)\n",
    "    \n",
    "    #loop throgh models\n",
    "    for i in range(len(pars)):\n",
    "            print((t,i))\n",
    "            ps = list(ParameterSampler(pars[i], n_iter=50, random_state=0))\n",
    "            if clfs_names[i] == 'RandomForestClassifier':\n",
    "                [d.update({'n_estimators':int(d['n_estimators'])}) for d in ps]\n",
    "            \n",
    "            #loop through model configs\n",
    "            for j in range(len(ps)):\n",
    "                print((t,i,j))\n",
    "                if [t,i,j] not in [list(map(int,re.findall(\"\\d+\",l[:10]))) for l in listdir(\"expanding_window/\")]:\n",
    "                    print((t,i,j))\n",
    "                    print(clfs[i])\n",
    "                    \n",
    "                    # generate an initialized model with the parameters sampled (ps)\n",
    "                    gs = clfs[i](**(ps[j]))\n",
    "                    try:\n",
    "                        get_p = gs.get_params(False)\n",
    "                    except:\n",
    "                        get_p = gs\n",
    "                    \n",
    "                    \n",
    "                    gs = gs.fit(X.values, y.values)\n",
    "                    y_proba = gs.predict_proba( X_k_test.values)\n",
    "\n",
    "                    pd.DataFrame(\\\n",
    "                                     {\n",
    "                                      'date':X_k_test_dates,\n",
    "                                      'y_proba':np.array(y_proba)[:,1],\n",
    "                                      'y_true':y_k_test.values}\n",
    "                                ).to_csv(f'expanding_window/{t,i,j}_{clfs_names[i]}.csv')\n",
    "                pd.Series({'Start_Test':time_frames.iloc[t].Start_Test,\n",
    "                            'get_p':str(get_p)}).to_csv(f'expanding_window/{t,i,j}_{clfs_names[i]}_date_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({'Start_Test':time_frames.iloc[t].Start_Test,\n",
    "'get_p':str(get_p)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(ParameterSampler(param_log_reg, n_iter=2, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(ParameterGrid(parameters3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC(**(list(ParameterGrid(parameters3))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "param_log_reg = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import expon\n",
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "param_grid = {'a':[1, 2], 'b': expon()}\n",
    "param_list = list(ParameterSampler(param_grid, n_iter=4, random_state=rng))\n",
    "rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
    "                 for d in param_list]\n",
    "rounded_list == [{'b': 0.89856, 'a': 1},\n",
    "                  {'b': 0.923223, 'a': 1},\n",
    "                  {'b': 1.878964, 'a': 2},\n",
    "                  {'b': 1.038159, 'a': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "    'module__num_units': [10, 20],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy')\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {'learning_rate': np.random.uniform(0, 1),\n",
    "          'boosting_type': np.random.choice(['gbdt', 'dart', 'goss']),\n",
    "          'objective': 'regression',\n",
    "          'metric' :'mae',\n",
    "          'sub_feature' : np.random.uniform(0, 1),\n",
    "          'num_leaves' : np.random.randint(20, 300),\n",
    "          'min_data' : np.random.randint(10, 100),\n",
    "          'max_depth' : np.random.randint(5, 200)}\n",
    "#iterations = np.random.randint(10, 10000)\n",
    "#clf = lgb.train(params, d_train, iterations)\n",
    "#y_pred=clf.predict(x_test) #Create predictions on test set\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'silent': [False],\n",
    "        'max_depth': [6, 10, 15, 20],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0,3],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "        'n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "{'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_gs = MLPClassifier(max_iter=100)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
