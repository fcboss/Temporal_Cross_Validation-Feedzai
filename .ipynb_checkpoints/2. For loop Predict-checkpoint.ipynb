{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:27:38.724207Z",
     "start_time": "2021-02-15T01:27:36.203222Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import re\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:27:46.387260Z",
     "start_time": "2021-02-15T01:27:40.811989Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data['as_of_date'] = pd.to_datetime(data.as_of_date)\n",
    "X,y = data.drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float),data['quickstart_label'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:27:50.844639Z",
     "start_time": "2021-02-15T01:27:50.810814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start_Train</th>\n",
       "      <th>Start_Threshold</th>\n",
       "      <th>Start_Test</th>\n",
       "      <th>End_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-02-01</td>\n",
       "      <td>2012-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Start_Train Start_Threshold  Start_Test    End_Test\n",
       "1           1  2011-10-01      2012-01-01  2012-02-01  2012-04-01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_frames = pd.read_csv('data/time_windows_frames.csv')\n",
    "\n",
    "time_frames.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-15T01:27:51.829Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-12-01\n",
      "0\n",
      "(0, 0)\n",
      "(0, 0, 0)\n",
      "(0, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 287 out of 287 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   33.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:   38.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=4)]: Done 1430 out of 1430 | elapsed:    5.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 2)\n",
      "(0, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:   23.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 859 out of 859 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 3)\n",
      "(0, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:   47.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done 986 out of 986 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 4)\n",
      "(0, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:   18.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 765 out of 765 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 5)\n",
      "(0, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   25.2s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done 1299 out of 1299 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 6)\n",
      "(0, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 161 out of 161 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 7)\n",
      "(0, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 138 out of 138 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 8)\n",
      "(0, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:   15.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 766 out of 766 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 9)\n",
      "(0, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   22.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 553 out of 553 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 10)\n",
      "(0, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 301 out of 301 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 11)\n",
      "(0, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:   56.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=4)]: Done 1599 out of 1599 | elapsed:    6.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 12)\n",
      "(0, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:   28.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 1081 out of 1081 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 13)\n",
      "(0, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=4)]: Done 1880 out of 1880 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 14)\n",
      "(0, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   33.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:   57.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=4)]: Done 1339 out of 1339 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 15)\n",
      "(0, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   48.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=4)]: Done 1915 out of 1915 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 16)\n",
      "(0, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:   51.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done 1644 out of 1644 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 17)\n",
      "(0, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 393 out of 393 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 18)\n",
      "(0, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 140 out of 140 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 19)\n",
      "(0, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:   45.8s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done 1182 out of 1182 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 20)\n",
      "(0, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:   24.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 788 out of 788 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 21)\n",
      "(0, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   13.6s\n"
     ]
    }
   ],
   "source": [
    "#loop through time split\n",
    "for t in range(time_frames.shape[0]):\n",
    "    date = time_frames.iloc[t].Start_Threshold\n",
    "    print(date)\n",
    "    print(t)\n",
    "    fold_data = data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ' )\n",
    "    \n",
    "    X = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "            .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "    y = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "            ['quickstart_label'].apply(int)\n",
    "    X_k_test = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "    X_k_test_dates = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            ['as_of_date']\n",
    "    y_k_test = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            ['quickstart_label'].apply(int)\n",
    "    \n",
    "    #loop throgh models\n",
    "    for i in range(len(pars)):\n",
    "            print((t,i))\n",
    "            ps = list(ParameterSampler(pars[i], n_iter=50, random_state=0))\n",
    "            if clfs_names[i] == 'RandomForestClassifier':\n",
    "                [d.update({'n_estimators':int(d['n_estimators'])}) for d in ps]\n",
    "            \n",
    "            #loop through model configs\n",
    "            for j in range(len(ps)):\n",
    "                print((t,i,j))\n",
    "                if [t,i,j] not in [list(map(int,re.findall(\"\\d+\",l[:10]))) for l in listdir(\"outputs_models3/\")]:\n",
    "                    print((t,i,j))\n",
    "                    print(clfs[i])\n",
    "                    \n",
    "                    # generate an initialized model with the parameters sampled (ps)\n",
    "                    gs = clfs[i](**(ps[j]))\n",
    "                    try:\n",
    "                        get_p = gs.get_params(False)\n",
    "                    except:\n",
    "                        get_p = gs\n",
    "                    \n",
    "                    gs = gs.fit(X.values, y.values)\n",
    "                    y_proba = gs.predict_proba( X_k_test.values)\n",
    "\n",
    "                    pd.DataFrame(\\\n",
    "                                     {\n",
    "                                      'date':X_k_test_dates,\n",
    "                                      'y_proba':np.array(y_proba)[:,1],\n",
    "                                      'y_true':y_k_test.values}\n",
    "                                ).to_csv(f'outputs_models3/{t,i,j}_{clfs_names[i]}.csv')\n",
    "                pd.Series({'Start_Test':time_frames.iloc[t].Start_Test,\n",
    "                            'get_p':str(get_p)}).to_csv(f'outputs_models3/{t,i,j}_{clfs_names[i]}_date_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({'Start_Test':time_frames.iloc[t].Start_Test,\n",
    "'get_p':str(get_p)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(ParameterSampler(param_log_reg, n_iter=2, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(ParameterGrid(parameters3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC(**(list(ParameterGrid(parameters3))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "param_log_reg = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import expon\n",
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "param_grid = {'a':[1, 2], 'b': expon()}\n",
    "param_list = list(ParameterSampler(param_grid, n_iter=4, random_state=rng))\n",
    "rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
    "                 for d in param_list]\n",
    "rounded_list == [{'b': 0.89856, 'a': 1},\n",
    "                  {'b': 0.923223, 'a': 1},\n",
    "                  {'b': 1.878964, 'a': 2},\n",
    "                  {'b': 1.038159, 'a': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "    'module__num_units': [10, 20],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy')\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {'learning_rate': np.random.uniform(0, 1),\n",
    "          'boosting_type': np.random.choice(['gbdt', 'dart', 'goss']),\n",
    "          'objective': 'regression',\n",
    "          'metric' :'mae',\n",
    "          'sub_feature' : np.random.uniform(0, 1),\n",
    "          'num_leaves' : np.random.randint(20, 300),\n",
    "          'min_data' : np.random.randint(10, 100),\n",
    "          'max_depth' : np.random.randint(5, 200)}\n",
    "#iterations = np.random.randint(10, 10000)\n",
    "#clf = lgb.train(params, d_train, iterations)\n",
    "#y_pred=clf.predict(x_test) #Create predictions on test set\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'silent': [False],\n",
    "        'max_depth': [6, 10, 15, 20],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0,3],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "        'n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "{'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_gs = MLPClassifier(max_iter=100)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
