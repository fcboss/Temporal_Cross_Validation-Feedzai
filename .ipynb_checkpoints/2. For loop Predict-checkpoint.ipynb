{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:46:02.307103Z",
     "start_time": "2021-02-15T01:46:02.253150Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import re\n",
    "from models import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:46:07.893635Z",
     "start_time": "2021-02-15T01:46:03.580937Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data['as_of_date'] = pd.to_datetime(data.as_of_date)\n",
    "X,y = data.drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float),data['quickstart_label'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T01:46:09.064506Z",
     "start_time": "2021-02-15T01:46:09.033504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Start_Train</th>\n",
       "      <th>Start_Threshold</th>\n",
       "      <th>Start_Test</th>\n",
       "      <th>End_Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Start_Train Start_Threshold  Start_Test    End_Test\n",
       "0           0  2011-09-01      2011-12-01  2012-01-01  2012-03-01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_frames = pd.read_csv('data/time_windows_frames.csv')\n",
    "\n",
    "time_frames.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T14:33:35.914792Z",
     "start_time": "2021-02-15T01:48:43.751552Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-12-01\n",
      "0\n",
      "(0, 0)\n",
      "(0, 0, 0)\n",
      "(0, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 1)\n",
      "(0, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:   30.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 2)\n",
      "(0, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 3)\n",
      "(0, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:   24.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 4)\n",
      "(0, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 5)\n",
      "(0, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:   28.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 6)\n",
      "(0, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 7)\n",
      "(0, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 8)\n",
      "(0, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 9)\n",
      "(0, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 10)\n",
      "(0, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 11)\n",
      "(0, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:   25.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 12)\n",
      "(0, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:   12.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 13)\n",
      "(0, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:   32.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 14)\n",
      "(0, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:   36.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 15)\n",
      "(0, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 16)\n",
      "(0, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:   24.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 17)\n",
      "(0, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 18)\n",
      "(0, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 19)\n",
      "(0, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 20)\n",
      "(0, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:   11.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 21)\n",
      "(0, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:   16.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 22)\n",
      "(0, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:   10.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 23)\n",
      "(0, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:    8.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 24)\n",
      "(0, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 25)\n",
      "(0, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 26)\n",
      "(0, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:   12.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 27)\n",
      "(0, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:   21.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 28)\n",
      "(0, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:   23.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 29)\n",
      "(0, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:   37.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 30)\n",
      "(0, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:   26.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 31)\n",
      "(0, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 32)\n",
      "(0, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:    3.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 33)\n",
      "(0, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 34)\n",
      "(0, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 35)\n",
      "(0, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 36)\n",
      "(0, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:   15.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 37)\n",
      "(0, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 38)\n",
      "(0, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:   38.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 39)\n",
      "(0, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:   18.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 40)\n",
      "(0, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 41)\n",
      "(0, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:   17.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 42)\n",
      "(0, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:   18.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 43)\n",
      "(0, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 44)\n",
      "(0, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:   34.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    4.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 45)\n",
      "(0, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 46)\n",
      "(0, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:   49.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 47)\n",
      "(0, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 48)\n",
      "(0, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   51.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:   55.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 49)\n",
      "(0, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   34.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:   38.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(0, 1, 0)\n",
      "(0, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 1)\n",
      "(0, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 2)\n",
      "(0, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 3)\n",
      "(0, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 4)\n",
      "(0, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 5)\n",
      "(0, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 6)\n",
      "(0, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 7)\n",
      "(0, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 8)\n",
      "(0, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 9)\n",
      "(0, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 10)\n",
      "(0, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 11)\n",
      "(0, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 12)\n",
      "(0, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 13)\n",
      "(0, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 14)\n",
      "(0, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 15)\n",
      "(0, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 16)\n",
      "(0, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 17)\n",
      "(0, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 18)\n",
      "(0, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 19)\n",
      "(0, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 20)\n",
      "(0, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 21)\n",
      "(0, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 22)\n",
      "(0, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 23)\n",
      "(0, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 24)\n",
      "(0, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 25)\n",
      "(0, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 26)\n",
      "(0, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 27)\n",
      "(0, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 28)\n",
      "(0, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 29)\n",
      "(0, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 30)\n",
      "(0, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 31)\n",
      "(0, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 32)\n",
      "(0, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 33)\n",
      "(0, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 34)\n",
      "(0, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 35)\n",
      "(0, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 36)\n",
      "(0, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 37)\n",
      "(0, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 38)\n",
      "(0, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 39)\n",
      "(0, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 40)\n",
      "(0, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 41)\n",
      "(0, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 42)\n",
      "(0, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 43)\n",
      "(0, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 44)\n",
      "(0, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 45)\n",
      "(0, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 46)\n",
      "(0, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 47)\n",
      "(0, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 48)\n",
      "(0, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 1, 49)\n",
      "(0, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(0, 2)\n",
      "(0, 2, 0)\n",
      "(0, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 1)\n",
      "(0, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 2)\n",
      "(0, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 3)\n",
      "(0, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 4)\n",
      "(0, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 5)\n",
      "(0, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 6)\n",
      "(0, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 7)\n",
      "(0, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 8)\n",
      "(0, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 9)\n",
      "(0, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 10)\n",
      "(0, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 11)\n",
      "(0, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 12)\n",
      "(0, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 13)\n",
      "(0, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 14)\n",
      "(0, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 15)\n",
      "(0, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 16)\n",
      "(0, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 17)\n",
      "(0, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 18)\n",
      "(0, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 19)\n",
      "(0, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 20)\n",
      "(0, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 21)\n",
      "(0, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 22)\n",
      "(0, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 23)\n",
      "(0, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 24)\n",
      "(0, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 25)\n",
      "(0, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 26)\n",
      "(0, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 27)\n",
      "(0, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 28)\n",
      "(0, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 29)\n",
      "(0, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 30)\n",
      "(0, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 31)\n",
      "(0, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 32)\n",
      "(0, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 33)\n",
      "(0, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 34)\n",
      "(0, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 35)\n",
      "(0, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 36)\n",
      "(0, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 37)\n",
      "(0, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 38)\n",
      "(0, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 39)\n",
      "(0, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 40)\n",
      "(0, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 41)\n",
      "(0, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 42)\n",
      "(0, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 43)\n",
      "(0, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 44)\n",
      "(0, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 45)\n",
      "(0, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 46)\n",
      "(0, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 47)\n",
      "(0, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 48)\n",
      "(0, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 2, 49)\n",
      "(0, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(0, 3)\n",
      "(0, 3, 0)\n",
      "(0, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 1)\n",
      "(0, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 2)\n",
      "(0, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 3)\n",
      "(0, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 4)\n",
      "(0, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 5)\n",
      "(0, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 6)\n",
      "(0, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 7)\n",
      "(0, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 8)\n",
      "(0, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 9)\n",
      "(0, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 10)\n",
      "(0, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 11)\n",
      "(0, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 12)\n",
      "(0, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 13)\n",
      "(0, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 14)\n",
      "(0, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 15)\n",
      "(0, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 16)\n",
      "(0, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 17)\n",
      "(0, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 18)\n",
      "(0, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 19)\n",
      "(0, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(0, 3, 20)\n",
      "(0, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 21)\n",
      "(0, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 22)\n",
      "(0, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 23)\n",
      "(0, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 24)\n",
      "(0, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 25)\n",
      "(0, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(0, 3, 26)\n",
      "(0, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 27)\n",
      "(0, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 28)\n",
      "(0, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 29)\n",
      "(0, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 30)\n",
      "(0, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 31)\n",
      "(0, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 32)\n",
      "(0, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 33)\n",
      "(0, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 34)\n",
      "(0, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 35)\n",
      "(0, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 36)\n",
      "(0, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 37)\n",
      "(0, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(0, 3, 38)\n",
      "(0, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 39)\n",
      "(0, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 40)\n",
      "(0, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 41)\n",
      "(0, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 42)\n",
      "(0, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 43)\n",
      "(0, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 44)\n",
      "(0, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 45)\n",
      "(0, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 46)\n",
      "(0, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 47)\n",
      "(0, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 48)\n",
      "(0, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 3, 49)\n",
      "(0, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(0, 4)\n",
      "(0, 4, 0)\n",
      "(0, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:28:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 1)\n",
      "(0, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 2)\n",
      "(0, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 3)\n",
      "(0, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 4)\n",
      "(0, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 5)\n",
      "(0, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 6)\n",
      "(0, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 7)\n",
      "(0, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 8)\n",
      "(0, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 9)\n",
      "(0, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 10)\n",
      "(0, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 11)\n",
      "(0, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 12)\n",
      "(0, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 13)\n",
      "(0, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 14)\n",
      "(0, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 15)\n",
      "(0, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 16)\n",
      "(0, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 17)\n",
      "(0, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 18)\n",
      "(0, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 19)\n",
      "(0, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 20)\n",
      "(0, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 21)\n",
      "(0, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 22)\n",
      "(0, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:30:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:30:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 23)\n",
      "(0, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:31:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 24)\n",
      "(0, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:31:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:31:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 25)\n",
      "(0, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:31:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:31:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 26)\n",
      "(0, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 27)\n",
      "(0, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 28)\n",
      "(0, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 29)\n",
      "(0, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 30)\n",
      "(0, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 31)\n",
      "(0, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 32)\n",
      "(0, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 33)\n",
      "(0, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 34)\n",
      "(0, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 35)\n",
      "(0, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:33:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 36)\n",
      "(0, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:33:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 37)\n",
      "(0, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:33:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 38)\n",
      "(0, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:33:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 39)\n",
      "(0, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:33:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 40)\n",
      "(0, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:33:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 41)\n",
      "(0, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:33:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:33:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 42)\n",
      "(0, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 43)\n",
      "(0, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 44)\n",
      "(0, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 45)\n",
      "(0, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 46)\n",
      "(0, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 47)\n",
      "(0, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 48)\n",
      "(0, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 4, 49)\n",
      "(0, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[01:34:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[01:34:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(0, 5)\n",
      "(0, 5, 0)\n",
      "(0, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 1)\n",
      "(0, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 2)\n",
      "(0, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 3)\n",
      "(0, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 4)\n",
      "(0, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 5)\n",
      "(0, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 6)\n",
      "(0, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 7)\n",
      "(0, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 8)\n",
      "(0, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 9)\n",
      "(0, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 10)\n",
      "(0, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 11)\n",
      "(0, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 12)\n",
      "(0, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 13)\n",
      "(0, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 14)\n",
      "(0, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 15)\n",
      "(0, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 16)\n",
      "(0, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 17)\n",
      "(0, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 18)\n",
      "(0, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 19)\n",
      "(0, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 20)\n",
      "(0, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 21)\n",
      "(0, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 22)\n",
      "(0, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 23)\n",
      "(0, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 24)\n",
      "(0, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 25)\n",
      "(0, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 26)\n",
      "(0, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 27)\n",
      "(0, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 28)\n",
      "(0, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 29)\n",
      "(0, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 30)\n",
      "(0, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 31)\n",
      "(0, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 32)\n",
      "(0, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 33)\n",
      "(0, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 34)\n",
      "(0, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 35)\n",
      "(0, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 36)\n",
      "(0, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 37)\n",
      "(0, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 38)\n",
      "(0, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 39)\n",
      "(0, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 40)\n",
      "(0, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 41)\n",
      "(0, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5, 42)\n",
      "(0, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 43)\n",
      "(0, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 44)\n",
      "(0, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 45)\n",
      "(0, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 46)\n",
      "(0, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 47)\n",
      "(0, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 48)\n",
      "(0, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 5, 49)\n",
      "(0, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(0, 6)\n",
      "(0, 6, 0)\n",
      "(0, 6, 0)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 1)\n",
      "(0, 6, 1)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 2)\n",
      "(0, 6, 2)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 3)\n",
      "(0, 6, 3)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 4)\n",
      "(0, 6, 4)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 5)\n",
      "(0, 6, 5)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 6)\n",
      "(0, 6, 6)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 7)\n",
      "(0, 6, 7)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 8)\n",
      "(0, 6, 8)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 9)\n",
      "(0, 6, 9)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 10)\n",
      "(0, 6, 10)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 11)\n",
      "(0, 6, 11)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 12)\n",
      "(0, 6, 12)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 13)\n",
      "(0, 6, 13)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 14)\n",
      "(0, 6, 14)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 15)\n",
      "(0, 6, 15)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 16)\n",
      "(0, 6, 16)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 17)\n",
      "(0, 6, 17)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 18)\n",
      "(0, 6, 18)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 19)\n",
      "(0, 6, 19)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 20)\n",
      "(0, 6, 20)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 21)\n",
      "(0, 6, 21)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 22)\n",
      "(0, 6, 22)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 23)\n",
      "(0, 6, 23)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 24)\n",
      "(0, 6, 24)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 25)\n",
      "(0, 6, 25)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 26)\n",
      "(0, 6, 26)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 27)\n",
      "(0, 6, 27)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 28)\n",
      "(0, 6, 28)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 29)\n",
      "(0, 6, 29)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 30)\n",
      "(0, 6, 30)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 31)\n",
      "(0, 6, 31)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 32)\n",
      "(0, 6, 32)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 33)\n",
      "(0, 6, 33)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 34)\n",
      "(0, 6, 34)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 35)\n",
      "(0, 6, 35)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 36)\n",
      "(0, 6, 36)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 37)\n",
      "(0, 6, 37)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 38)\n",
      "(0, 6, 38)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 39)\n",
      "(0, 6, 39)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 40)\n",
      "(0, 6, 40)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 41)\n",
      "(0, 6, 41)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 42)\n",
      "(0, 6, 42)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 43)\n",
      "(0, 6, 43)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 44)\n",
      "(0, 6, 44)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 45)\n",
      "(0, 6, 45)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 46)\n",
      "(0, 6, 46)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 47)\n",
      "(0, 6, 47)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 48)\n",
      "(0, 6, 48)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 6, 49)\n",
      "(0, 6, 49)\n",
      "<class 'sklearn.svm._classes.SVC'>\n",
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-01-01\n",
      "1\n",
      "(1, 0)\n",
      "(1, 0, 0)\n",
      "(1, 0, 0)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 287 out of 287 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 287 out of 287 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 1)\n",
      "(1, 0, 1)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1430 out of 1430 | elapsed:   24.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=12)]: Done 1430 out of 1430 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 2)\n",
      "(1, 0, 2)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done 859 out of 859 | elapsed:   12.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 859 out of 859 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 3)\n",
      "(1, 0, 3)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 986 out of 986 | elapsed:   21.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 986 out of 986 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 4)\n",
      "(1, 0, 4)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 765 out of 765 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 765 out of 765 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 5)\n",
      "(1, 0, 5)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1299 out of 1299 | elapsed:   35.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 1299 out of 1299 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 6)\n",
      "(1, 0, 6)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 161 out of 161 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 7)\n",
      "(1, 0, 7)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 138 out of 138 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 138 out of 138 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 8)\n",
      "(1, 0, 8)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 766 out of 766 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 766 out of 766 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 9)\n",
      "(1, 0, 9)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done 553 out of 553 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 553 out of 553 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 10)\n",
      "(1, 0, 10)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 11)\n",
      "(1, 0, 11)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1599 out of 1599 | elapsed:   26.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 1599 out of 1599 | elapsed:    2.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 12)\n",
      "(1, 0, 12)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1081 out of 1081 | elapsed:   14.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1081 out of 1081 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 13)\n",
      "(1, 0, 13)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1880 out of 1880 | elapsed:   30.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1880 out of 1880 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 14)\n",
      "(1, 0, 14)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1339 out of 1339 | elapsed:   32.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 1339 out of 1339 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 15)\n",
      "(1, 0, 15)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   40.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1915 out of 1915 | elapsed:   44.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=12)]: Done 1915 out of 1915 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 16)\n",
      "(1, 0, 16)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1644 out of 1644 | elapsed:   23.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1644 out of 1644 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 17)\n",
      "(1, 0, 17)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 393 out of 393 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 393 out of 393 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 18)\n",
      "(1, 0, 18)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 140 out of 140 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 19)\n",
      "(1, 0, 19)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1182 out of 1182 | elapsed:   21.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1182 out of 1182 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 20)\n",
      "(1, 0, 20)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 788 out of 788 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 788 out of 788 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 21)\n",
      "(1, 0, 21)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1114 out of 1114 | elapsed:   17.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 1114 out of 1114 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 22)\n",
      "(1, 0, 22)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1405 out of 1405 | elapsed:   12.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 1405 out of 1405 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 23)\n",
      "(1, 0, 23)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 647 out of 647 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 647 out of 647 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 24)\n",
      "(1, 0, 24)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 306 out of 306 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 25)\n",
      "(1, 0, 25)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 190 out of 190 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 190 out of 190 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 26)\n",
      "(1, 0, 26)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1030 out of 1030 | elapsed:   10.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1030 out of 1030 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 27)\n",
      "(1, 0, 27)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:   22.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 28)\n",
      "(1, 0, 28)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 896 out of 896 | elapsed:   21.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 896 out of 896 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 29)\n",
      "(1, 0, 29)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1262 out of 1262 | elapsed:   31.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=12)]: Done 1262 out of 1262 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 30)\n",
      "(1, 0, 30)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1186 out of 1186 | elapsed:   28.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1186 out of 1186 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 31)\n",
      "(1, 0, 31)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 out of 176 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 out of 176 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 32)\n",
      "(1, 0, 32)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 226 out of 226 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 226 out of 226 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 33)\n",
      "(1, 0, 33)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 301 out of 301 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 301 out of 301 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 34)\n",
      "(1, 0, 34)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1650 out of 1650 | elapsed:   26.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1650 out of 1650 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 35)\n",
      "(1, 0, 35)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 633 out of 633 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 633 out of 633 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 36)\n",
      "(1, 0, 36)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1208 out of 1208 | elapsed:   15.4s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 1208 out of 1208 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 37)\n",
      "(1, 0, 37)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 307 out of 307 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 307 out of 307 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 38)\n",
      "(1, 0, 38)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1833 out of 1833 | elapsed:   45.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=12)]: Done 1833 out of 1833 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 39)\n",
      "(1, 0, 39)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1078 out of 1078 | elapsed:   22.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 1078 out of 1078 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 40)\n",
      "(1, 0, 40)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 777 out of 777 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 777 out of 777 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 41)\n",
      "(1, 0, 41)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1480 out of 1480 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1480 out of 1480 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 42)\n",
      "(1, 0, 42)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1410 out of 1410 | elapsed:   25.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=12)]: Done 1410 out of 1410 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 43)\n",
      "(1, 0, 43)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 333 out of 333 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 333 out of 333 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 44)\n",
      "(1, 0, 44)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1323 out of 1323 | elapsed:   25.7s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1323 out of 1323 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 45)\n",
      "(1, 0, 45)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 566 out of 566 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 566 out of 566 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 46)\n",
      "(1, 0, 46)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1696 out of 1696 | elapsed:   44.5s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done 1696 out of 1696 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 47)\n",
      "(1, 0, 47)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  53 out of  53 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 48)\n",
      "(1, 0, 48)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1891 out of 1891 | elapsed:   45.3s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1891 out of 1891 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 49)\n",
      "(1, 0, 49)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1988 out of 1988 | elapsed:   34.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=12)]: Done 1988 out of 1988 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1, 0)\n",
      "(1, 1, 0)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 1)\n",
      "(1, 1, 1)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 2)\n",
      "(1, 1, 2)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 3)\n",
      "(1, 1, 3)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 4)\n",
      "(1, 1, 4)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 5)\n",
      "(1, 1, 5)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 6)\n",
      "(1, 1, 6)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 7)\n",
      "(1, 1, 7)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 8)\n",
      "(1, 1, 8)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 9)\n",
      "(1, 1, 9)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 10)\n",
      "(1, 1, 10)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 11)\n",
      "(1, 1, 11)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 12)\n",
      "(1, 1, 12)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 13)\n",
      "(1, 1, 13)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 14)\n",
      "(1, 1, 14)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 15)\n",
      "(1, 1, 15)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 16)\n",
      "(1, 1, 16)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 17)\n",
      "(1, 1, 17)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 18)\n",
      "(1, 1, 18)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 19)\n",
      "(1, 1, 19)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 20)\n",
      "(1, 1, 20)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 21)\n",
      "(1, 1, 21)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 22)\n",
      "(1, 1, 22)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 23)\n",
      "(1, 1, 23)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 24)\n",
      "(1, 1, 24)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 25)\n",
      "(1, 1, 25)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 26)\n",
      "(1, 1, 26)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 27)\n",
      "(1, 1, 27)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 28)\n",
      "(1, 1, 28)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 29)\n",
      "(1, 1, 29)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 30)\n",
      "(1, 1, 30)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 31)\n",
      "(1, 1, 31)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 32)\n",
      "(1, 1, 32)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 33)\n",
      "(1, 1, 33)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 34)\n",
      "(1, 1, 34)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 35)\n",
      "(1, 1, 35)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 36)\n",
      "(1, 1, 36)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 37)\n",
      "(1, 1, 37)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 38)\n",
      "(1, 1, 38)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 39)\n",
      "(1, 1, 39)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 40)\n",
      "(1, 1, 40)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 41)\n",
      "(1, 1, 41)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 42)\n",
      "(1, 1, 42)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 43)\n",
      "(1, 1, 43)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 44)\n",
      "(1, 1, 44)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 45)\n",
      "(1, 1, 45)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 46)\n",
      "(1, 1, 46)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 47)\n",
      "(1, 1, 47)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 48)\n",
      "(1, 1, 48)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 1, 49)\n",
      "(1, 1, 49)\n",
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "(1, 2)\n",
      "(1, 2, 0)\n",
      "(1, 2, 0)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 1)\n",
      "(1, 2, 1)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 2)\n",
      "(1, 2, 2)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 3)\n",
      "(1, 2, 3)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 4)\n",
      "(1, 2, 4)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 5)\n",
      "(1, 2, 5)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 6)\n",
      "(1, 2, 6)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 7)\n",
      "(1, 2, 7)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 8)\n",
      "(1, 2, 8)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 9)\n",
      "(1, 2, 9)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 10)\n",
      "(1, 2, 10)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 11)\n",
      "(1, 2, 11)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 12)\n",
      "(1, 2, 12)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 13)\n",
      "(1, 2, 13)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 14)\n",
      "(1, 2, 14)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 15)\n",
      "(1, 2, 15)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 16)\n",
      "(1, 2, 16)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 17)\n",
      "(1, 2, 17)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 18)\n",
      "(1, 2, 18)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 19)\n",
      "(1, 2, 19)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 20)\n",
      "(1, 2, 20)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 21)\n",
      "(1, 2, 21)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 22)\n",
      "(1, 2, 22)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 23)\n",
      "(1, 2, 23)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 24)\n",
      "(1, 2, 24)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 25)\n",
      "(1, 2, 25)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 26)\n",
      "(1, 2, 26)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 27)\n",
      "(1, 2, 27)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 28)\n",
      "(1, 2, 28)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 29)\n",
      "(1, 2, 29)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 30)\n",
      "(1, 2, 30)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 31)\n",
      "(1, 2, 31)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 32)\n",
      "(1, 2, 32)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 33)\n",
      "(1, 2, 33)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 34)\n",
      "(1, 2, 34)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 35)\n",
      "(1, 2, 35)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 36)\n",
      "(1, 2, 36)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 37)\n",
      "(1, 2, 37)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 38)\n",
      "(1, 2, 38)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 39)\n",
      "(1, 2, 39)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 40)\n",
      "(1, 2, 40)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 41)\n",
      "(1, 2, 41)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 42)\n",
      "(1, 2, 42)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 43)\n",
      "(1, 2, 43)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 44)\n",
      "(1, 2, 44)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 45)\n",
      "(1, 2, 45)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 46)\n",
      "(1, 2, 46)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 47)\n",
      "(1, 2, 47)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 48)\n",
      "(1, 2, 48)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 2, 49)\n",
      "(1, 2, 49)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "(1, 3)\n",
      "(1, 3, 0)\n",
      "(1, 3, 0)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=217, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7292881023563949, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 1)\n",
      "(1, 3, 1)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=187, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6306290243756199, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 2)\n",
      "(1, 3, 2)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=188, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7173369518517427, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 3)\n",
      "(1, 3, 3)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=297, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6209449239043288, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 4)\n",
      "(1, 3, 4)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=388, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8073277180713763, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 5)\n",
      "(1, 3, 5)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=470, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6841602516079945, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 6)\n",
      "(1, 3, 6)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=344, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7672574336334528, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 7)\n",
      "(1, 3, 7)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=157, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9414091499043905, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 8)\n",
      "(1, 3, 8)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=153, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5892570105545103, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 9)\n",
      "(1, 3, 9)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=456, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.49678571073099775, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 10)\n",
      "(1, 3, 10)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=473, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.602804568903335, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 11)\n",
      "(1, 3, 11)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=278, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4582607654758368, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 12)\n",
      "(1, 3, 12)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=301, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4334288162209638, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 13)\n",
      "(1, 3, 13)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=198, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.47123663137254646, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 14)\n",
      "(1, 3, 14)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=370, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5592336945636672, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 15)\n",
      "(1, 3, 15)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=132, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4790787174426353, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 16)\n",
      "(1, 3, 16)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=177, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4989642761451305, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 17)\n",
      "(1, 3, 17)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=119, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5492518861119748, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 18)\n",
      "(1, 3, 18)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=360, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6682752271705764, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 19)\n",
      "(1, 3, 19)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=252, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928661918266697, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(1, 3, 20)\n",
      "(1, 3, 20)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=460, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5383198141037979, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 21)\n",
      "(1, 3, 21)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=284, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.796104122495611, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 22)\n",
      "(1, 3, 22)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=449, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.45542433367653895, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 23)\n",
      "(1, 3, 23)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5327576111102696, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 24)\n",
      "(1, 3, 24)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=204, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4601361323873807, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 25)\n",
      "(1, 3, 25)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=127, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4225356302968842, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(1, 3, 26)\n",
      "(1, 3, 26)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=135, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7414604431687559, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 27)\n",
      "(1, 3, 27)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.43035286903254233, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 28)\n",
      "(1, 3, 28)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=233, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6937293621346563, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 29)\n",
      "(1, 3, 29)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=236, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9664718505505381, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 30)\n",
      "(1, 3, 30)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=125, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5427356928247051, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 31)\n",
      "(1, 3, 31)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=373, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9786938606736585, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 32)\n",
      "(1, 3, 32)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=191, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6942752851705403, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 33)\n",
      "(1, 3, 33)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=448, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.928602737321005, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 34)\n",
      "(1, 3, 34)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=429, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6722181067336273, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 35)\n",
      "(1, 3, 35)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=124, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.48233225205831676, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 36)\n",
      "(1, 3, 36)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=260, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.7118267161949657, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 37)\n",
      "(1, 3, 37)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=420, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9716749941831667, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "(1, 3, 38)\n",
      "(1, 3, 38)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=122, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9744705133953723, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 39)\n",
      "(1, 3, 39)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=239, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.528928442050347, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 40)\n",
      "(1, 3, 40)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=407, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8301158087155562, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 41)\n",
      "(1, 3, 41)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=411, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.4748998344940516, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 42)\n",
      "(1, 3, 42)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=254, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8390162538788143, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 43)\n",
      "(1, 3, 43)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=113, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.40554404409192446, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 44)\n",
      "(1, 3, 44)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=362, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.6913765575607738, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 45)\n",
      "(1, 3, 45)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=251, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.9273218450664825, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 46)\n",
      "(1, 3, 46)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=453, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.575812170704678, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 47)\n",
      "(1, 3, 47)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=107, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.989097633890952, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 48)\n",
      "(1, 3, 48)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=359, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.5787050911330338, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 3, 49)\n",
      "(1, 3, 49)\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LightGBM] [Warning] min_data_in_leaf is set with min_child_samples=447, will be overridden by min_data=43. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] feature_fraction is set with colsample_bytree=0.8733236666316784, will be overridden by sub_feature=0.052510567873184866. Current value: feature_fraction=0.052510567873184866\n",
      "(1, 4)\n",
      "(1, 4, 0)\n",
      "(1, 4, 0)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:17:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:17:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 1)\n",
      "(1, 4, 1)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:17:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:17:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 2)\n",
      "(1, 4, 2)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:17:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:17:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 3)\n",
      "(1, 4, 3)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:17:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:17:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 4)\n",
      "(1, 4, 4)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 5)\n",
      "(1, 4, 5)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 6)\n",
      "(1, 4, 6)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 7)\n",
      "(1, 4, 7)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 8)\n",
      "(1, 4, 8)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 9)\n",
      "(1, 4, 9)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 10)\n",
      "(1, 4, 10)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 11)\n",
      "(1, 4, 11)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:18:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:18:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 12)\n",
      "(1, 4, 12)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:19:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:19:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 13)\n",
      "(1, 4, 13)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:19:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:19:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 14)\n",
      "(1, 4, 14)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:19:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:19:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 15)\n",
      "(1, 4, 15)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:19:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:19:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 16)\n",
      "(1, 4, 16)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:19:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:19:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 17)\n",
      "(1, 4, 17)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:19:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:19:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 18)\n",
      "(1, 4, 18)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:20:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 19)\n",
      "(1, 4, 19)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:20:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 20)\n",
      "(1, 4, 20)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:20:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 21)\n",
      "(1, 4, 21)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:20:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 22)\n",
      "(1, 4, 22)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:20:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 23)\n",
      "(1, 4, 23)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:20:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 24)\n",
      "(1, 4, 24)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:20:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:20:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 25)\n",
      "(1, 4, 25)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:21:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:21:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 26)\n",
      "(1, 4, 26)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:21:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:21:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 27)\n",
      "(1, 4, 27)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:21:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:21:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 28)\n",
      "(1, 4, 28)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:21:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:21:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 29)\n",
      "(1, 4, 29)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:21:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 30)\n",
      "(1, 4, 30)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:21:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:21:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 31)\n",
      "(1, 4, 31)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 32)\n",
      "(1, 4, 32)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 33)\n",
      "(1, 4, 33)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 34)\n",
      "(1, 4, 34)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 35)\n",
      "(1, 4, 35)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 36)\n",
      "(1, 4, 36)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 37)\n",
      "(1, 4, 37)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 38)\n",
      "(1, 4, 38)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:22:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 39)\n",
      "(1, 4, 39)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 40)\n",
      "(1, 4, 40)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 41)\n",
      "(1, 4, 41)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 42)\n",
      "(1, 4, 42)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 43)\n",
      "(1, 4, 43)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 44)\n",
      "(1, 4, 44)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 45)\n",
      "(1, 4, 45)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 46)\n",
      "(1, 4, 46)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 47)\n",
      "(1, 4, 47)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:23:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:23:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 48)\n",
      "(1, 4, 48)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:24:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:24:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 4, 49)\n",
      "(1, 4, 49)\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "[02:24:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[02:24:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "(1, 5)\n",
      "(1, 5, 0)\n",
      "(1, 5, 0)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 1)\n",
      "(1, 5, 1)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 2)\n",
      "(1, 5, 2)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 3)\n",
      "(1, 5, 3)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 4)\n",
      "(1, 5, 4)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 5)\n",
      "(1, 5, 5)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 6)\n",
      "(1, 5, 6)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 7)\n",
      "(1, 5, 7)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 8)\n",
      "(1, 5, 8)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 9)\n",
      "(1, 5, 9)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 10)\n",
      "(1, 5, 10)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 11)\n",
      "(1, 5, 11)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 12)\n",
      "(1, 5, 12)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 13)\n",
      "(1, 5, 13)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 14)\n",
      "(1, 5, 14)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 15)\n",
      "(1, 5, 15)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 16)\n",
      "(1, 5, 16)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 17)\n",
      "(1, 5, 17)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 18)\n",
      "(1, 5, 18)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 19)\n",
      "(1, 5, 19)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 20)\n",
      "(1, 5, 20)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 21)\n",
      "(1, 5, 21)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 22)\n",
      "(1, 5, 22)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 23)\n",
      "(1, 5, 23)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 24)\n",
      "(1, 5, 24)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 25)\n",
      "(1, 5, 25)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 26)\n",
      "(1, 5, 26)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 27)\n",
      "(1, 5, 27)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 28)\n",
      "(1, 5, 28)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 29)\n",
      "(1, 5, 29)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 30)\n",
      "(1, 5, 30)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 31)\n",
      "(1, 5, 31)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 32)\n",
      "(1, 5, 32)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 33)\n",
      "(1, 5, 33)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 34)\n",
      "(1, 5, 34)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 35)\n",
      "(1, 5, 35)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 36)\n",
      "(1, 5, 36)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 37)\n",
      "(1, 5, 37)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 38)\n",
      "(1, 5, 38)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 39)\n",
      "(1, 5, 39)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fld\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 40)\n",
      "(1, 5, 40)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 41)\n",
      "(1, 5, 41)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 42)\n",
      "(1, 5, 42)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 43)\n",
      "(1, 5, 43)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 44)\n",
      "(1, 5, 44)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 45)\n",
      "(1, 5, 45)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 46)\n",
      "(1, 5, 46)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 47)\n",
      "(1, 5, 47)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 48)\n",
      "(1, 5, 48)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n",
      "(1, 5, 49)\n",
      "(1, 5, 49)\n",
      "<class 'sklearn.neural_network._multilayer_perceptron.MLPClassifier'>\n"
     ]
    }
   ],
   "source": [
    "#loop through time split\n",
    "for t in range(time_frames.shape[0]):\n",
    "    date = time_frames.iloc[t].Start_Threshold\n",
    "    print(date)\n",
    "    print(t)\n",
    "    \n",
    "#     fold_data = data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ' )\n",
    "    \n",
    "#     X = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "#             .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "#     y = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Train}\" & as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "#             ['quickstart_label'].apply(int)\n",
    "    \n",
    "    fold_data = data.query(f' as_of_date <= \"{time_frames.iloc[t].End_Test}\" ' )\n",
    "    \n",
    "    X = fold_data.query(f' as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "            .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "    y = fold_data.query(f'as_of_date <= \"{time_frames.iloc[t].Start_Threshold}\" ')\\\n",
    "            ['quickstart_label'].apply(int)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    X_k_test = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            .drop(['Unnamed: 0','entity_id','as_of_date','quickstart_label'],axis=1).applymap(float)\n",
    "    X_k_test_dates = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            ['as_of_date']\n",
    "    y_k_test = fold_data.query(f'as_of_date > \"{time_frames.iloc[t].Start_Threshold}\" & as_of_date <= \"{time_frames.iloc[t].End_Test}\" ')\\\n",
    "            ['quickstart_label'].apply(int)\n",
    "    \n",
    "    #loop throgh models\n",
    "    for i in range(len(pars)):\n",
    "            print((t,i))\n",
    "            ps = list(ParameterSampler(pars[i], n_iter=50, random_state=0))\n",
    "            if clfs_names[i] == 'RandomForestClassifier':\n",
    "                [d.update({'n_estimators':int(d['n_estimators'])}) for d in ps]\n",
    "            \n",
    "            #loop through model configs\n",
    "            for j in range(len(ps)):\n",
    "                print((t,i,j))\n",
    "                if [t,i,j] not in [list(map(int,re.findall(\"\\d+\",l[:10]))) for l in listdir(\"expanding_window/\")]:\n",
    "                    print((t,i,j))\n",
    "                    print(clfs[i])\n",
    "                    \n",
    "                    # generate an initialized model with the parameters sampled (ps)\n",
    "                    gs = clfs[i](**(ps[j]))\n",
    "                    try:\n",
    "                        get_p = gs.get_params(False)\n",
    "                    except:\n",
    "                        get_p = gs\n",
    "                    \n",
    "                    \n",
    "                    gs = gs.fit(X.values, y.values)\n",
    "                    y_proba = gs.predict_proba( X_k_test.values)\n",
    "\n",
    "                    pd.DataFrame(\\\n",
    "                                     {\n",
    "                                      'date':X_k_test_dates,\n",
    "                                      'y_proba':np.array(y_proba)[:,1],\n",
    "                                      'y_true':y_k_test.values}\n",
    "                                ).to_csv(f'expanding_window/{t,i,j}_{clfs_names[i]}.csv')\n",
    "                pd.Series({'Start_Test':time_frames.iloc[t].Start_Test,\n",
    "                            'get_p':str(get_p)}).to_csv(f'expanding_window/{t,i,j}_{clfs_names[i]}_date_params.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.Series({'Start_Test':time_frames.iloc[t].Start_Test,\n",
    "'get_p':str(get_p)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(ParameterSampler(param_log_reg, n_iter=2, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(ParameterGrid(parameters3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC(**(list(ParameterGrid(parameters3))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "                              random_state=0)\n",
    "param_log_reg = dict(C=uniform(loc=0, scale=4),\n",
    "                     penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, distributions, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats.distributions import expon\n",
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "param_grid = {'a':[1, 2], 'b': expon()}\n",
    "param_list = list(ParameterSampler(param_grid, n_iter=4, random_state=rng))\n",
    "rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
    "                 for d in param_list]\n",
    "rounded_list == [{'b': 0.89856, 'a': 1},\n",
    "                  {'b': 0.923223, 'a': 1},\n",
    "                  {'b': 1.878964, 'a': 2},\n",
    "                  {'b': 1.038159, 'a': 2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "    'module__num_units': [10, 20],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy')\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "params = {'learning_rate': np.random.uniform(0, 1),\n",
    "          'boosting_type': np.random.choice(['gbdt', 'dart', 'goss']),\n",
    "          'objective': 'regression',\n",
    "          'metric' :'mae',\n",
    "          'sub_feature' : np.random.uniform(0, 1),\n",
    "          'num_leaves' : np.random.randint(20, 300),\n",
    "          'min_data' : np.random.randint(10, 100),\n",
    "          'max_depth' : np.random.randint(5, 200)}\n",
    "#iterations = np.random.randint(10, 10000)\n",
    "#clf = lgb.train(params, d_train, iterations)\n",
    "#y_pred=clf.predict(x_test) #Create predictions on test set\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'silent': [False],\n",
    "        'max_depth': [6, 10, 15, 20],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0,3],\n",
    "        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'reg_lambda': [0.1, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "        'n_estimators': [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "{'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_gs = MLPClassifier(max_iter=100)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
